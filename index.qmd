---
title: "Causes and effects in Dichotomous Comparative Judgments: an information-theoretical system of plausible mechanism"
author:
  - name: 
      given: Jose Manuel
      family: Rivera Espejo
    orcid: 0000-0002-3088-2783
    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/
    email: JoseManuel.RiveraEspejo@uantwerpen.be
    corresponding: true
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: lead
      - methodology: lead
      - software: only
      - validation: only
      - formal analysis: only
      - investigation: only
      - resources: no
      - data curation: only
      - writing: only
      - editing: no
      - visualization: only
      - supervision: no
      - project administration: no
      - funding adquisition: no
  - name: 
      given: Tine
      family: van Daal
      non-dropping-particle: van
    orcid: https://orcid.org/0000-0001-9398-9775
    url: https://www.uantwerpen.be/en/staff/tine-vandaal/
    email: tine.vandaal@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: support
      - methodology: support
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: no
      - project administration: no
      - funding adquisition: no
  - name: 
      given: Sven
      family: De Maeyer
      non-dropping-particle: De
    orcid: 0000-0003-2888-1631
    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/
    email: sven.demaeyer@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: support
      - methodology: support
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: yes
      - project administration: yes
      - funding adquisition: yes
  - name: 
      given: Steven
      family: Gillis
    orcid: 
    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/
    email: steven.gillis@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Linguistics
        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)
    roles: 
      - conceptualization: support
      - methodology: no
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: yes
      - project administration: yes
      - funding adquisition: yes
funding: 
  statement: "The project was founded through the Research Fund of the University of Antwerp (BOF)."
keywords:
  - causal inference
  - probability
  - Thurstone
  - comparative judgement
  - directed acyclic graph
  - structural causal models
  - statistical modeling
abstract: |
  Dichotomous Comparative Judgment (DCJ) requires judges to compare pairs of stimuli to determine which one exhibits a higher degree of a specific trait. DCJ has proven effective and reliable across various fields [@Pollitt_2012b; @Jones_2015; @vanDaal_et_al_2016; @Bartholomew_et_al_2018; @Lesterhuis_2018; @Bartholomew_et_al_2020; @Marshall_et_al_2020; @Boonen_et_al_2020]. However, despite the method's widespread use, existing literature lacks a clear explanation of the complexities and assumptions underpinning the DCJ system, as well as the plausible mechanisms through which DCJ data could be generated. This study addresses these issues by representing DCJ within the framework of causal inference. Specifically, utilizing the structural approach, the study develops a scientific model to clarify plausible causal assumptions and mechanisms inherent in the DCJ system. The study then translates this model into a probabilistic statistical model to estimate statistical relationships and infer causal effects within the system. This research provides a robust probabilistic foundation for the statistical analysis of DCJ data, building upon Thurstone’s law of comparative judgment [-@Thurstone_1927]. Its findings offer valuable insights for researchers and analysts designing and implementing DCJ experiments.
key-points:
  - (to do)
date: last-modified
bibliography: references.bib
notebook-links: global
lightbox: true
citation: true
  # type: article-journal
  # container-title: "Psychometrika"
  # doi: ""
  # # url: https://example.com/summarizing-output
execute: 
  cache: true
  # eval: true
  echo: false
  # output: true
  # include: true
  warning: false
  error: false
  message: false
---

# Introduction {#sec-introduction}

<!-- 1. What is comparative judgment? -->
In contemporary contexts, Thurstone's law of comparative judgment [-@Thurstone_1927] primarily refers to the method of *dichotomous* comparative judgment [DCJ, @Pollitt_2012a; @Pollitt_2012b]. In DCJ, a judge assesses the relative manifestation of a *trait* within a pair of stimuli. This assessment results in a dichotomous value indicating which stimulus possesses a higher degree of the trait. After different judges perform multiple rounds of pairwise comparisons, an outcome vector is produced. This vector is modeled using the Bradley-Terry-Luce model [BTL, @Bradley_et_al_1952; @Luce_1959], which creates a score that corresponds with the trait of interest. This score is then used to rank the stimuli from lowest to highest or to evaluate the influence of certain variables on the stimuli's positions in the ranking.

<!-- 2. in what has been applied on?, and where is the gap? -->
DCJ has proven effective in assessing competencies and traits predominantly within the educational realm, as demonstrated by @Pollitt_2012b, @Jones_2015, @vanDaal_et_al_2016, @Bartholomew_et_al_2018, @Lesterhuis_2018, @Bartholomew_et_al_2020, and @Marshall_et_al_2020. However, its application transcends education, as exemplified by @Boonen_et_al_2020. The methodology has also evolved to include multiple, as opposed to pairwise comparisons [@Luce_1959; @Placket_1975], and to accommodate comparisons with ordinal outcomes [@Tutz_1986; @Agresti_1992]. Overall, research suggests that DCJ offers an alternative and efficient approach to measurement and evaluation, characterized by its reliability and validity [@Lesterhuis_2018; @vanDaal_2020; @Marshall_et_al_2020; @Bouwer_et_al_2023]. Nevertheless, despite the method's widespread use, existing literature lacks a clear representation of the plausible mechanisms through which DCJ data could be generated. Particularly, there is no depiction of the complexity and the assumptions underpinning the DCJ system, nor how different assessment factors can potentially influence the observed DCJ outcome.

<!-- 3. What are the factors behind DCJ? -->
According to @Verhavert_et_al_2019 and @vanDaal_2020, several assessment factors interact and influence the method's outcome. These factors include the number and characteristics of the stimuli, their *proximity* in terms of the assessed trait, the number of comparison per stimulus, and the pairing algorithm used. Furthermore, since the method relies on judges' assessments, the number and characteristics of judges, their *discrimination* abilities, and the number of comparisons per judge also play pivotal roles. Moreover, when the stimuli represent sub-units of higher-levels units, factors such as the number and characteristics of these units, along with their *proximity* in terms of the assessed trait, can significantly influence the outcome. For instance, @vanDaal_et_al_2016 assessed academic writing skills of university students (units) using multiple argumentative essays (sub-units).

<!-- 4. Solution to the gap -->
Although several studies have examined the individual impact of these factors on the method's reliability [@Bramley_2015; @Pollitt_2012b; @Bramley_et_al_2019; @Verhavert_et_al_2019; @Crompvoets_et_al_2022; @vanDaal_et_al_2017; @Gijsen_et_al_2021; @Bouwer_et_al_2023], none, to the best of the authors' knowledge, have provided a transparent depiction of the DCJ system and the mechanisms generating the DCJ outcome. This study aims to fill this gap by representing DCJ within the framework of causal inference. Specifically, utilizing the structural approach [@Wright_1921; @Pearl_2009; @Pearl_et_al_2016], the study develops a scientific model to clarify plausible causal assumptions and mechanisms inherent in the DCJ system. The study then translates the scientific model into a probabilistic statistical model. This model aims to produce statistical estimates to draw inferences about plausible causal relationships within the DCJ system. 

<!-- 5. final objective and relevance -->
Ultimately, this study provides a robust causal and probabilistic foundation for the statistical analysis of DCJ data, building upon Thurstone’s law of comparative judgment [-@Thurstone_1927]. Consequently, its findings offer valuable insights for researchers and analysts designing and implementing DCJ experiments.


# Theoretical framework {#sec-framework}

This section introduces fundamental concepts in causal inference, such as directed acyclic graphs (DAGs), structural causal models (SCMs), and the flow of association and causation in graphs. The section is not a comprehensive description of causal inference methods. Readers interested in deeper exploration should consult introductory papers like @Pearl_2010, @Rohrer_2018, @Pearl_2019, and @Cinelli_et_al_2020. They may also find introductory books such as @Pearl_et_al_2018, @Neal_2020 and @McElreath_2020 useful. For more advanced study, seminal intermediate papers like @Neyman_et_al_1923, @Rubin_1974, @Spirtes_et_al_1991, and @Sekhon_2009, as well as books such as @Pearl_2009, @Morgan_et_al_2014 and @Hernan_et_al_2020 are recommended.

## The structural approach to causal inference {#sec-framework-structural}

<!-- 1. What is causal inference? -->
In statistics, *causal inference* refers to the process of identifying the causes of a phenomenon and estimating their effects using data [@Shaughnessy_et_al_2010; @Neal_2020]. Unlike classical statistical modeling, which focuses solely on summarizing data and inferring associations, causal inference provides a coherent mathematical notation for analyzing causes and counterfactuals [@Pearl_2009]. 

<!-- 2. what are counterfactuals? -->
Counterfactuals represent scenarios *contrary to fact*, where alternative *potential* outcomes resulting from a cause are neither observed nor observable [@Neal_2020; @Counterfactual_2024]. According to @Pearl_et_al_2018, counterfactuals are the foundation of causal inference and occupy the highest level of cognitive abstraction in the ladder of causation, followed by intervention and association. Nevertheless, despite their abstract nature, counterfactuals enable the development of a *theory of the world* that explains why specific causes have specific effects and what occurs in their absence [@Pearl_et_al_2018]. They achieve this by translating causal statements into counterfactual statements, that is, statements about "what would have happened in the world under different circumstances."

<!-- 3. How do we apply causal inference and counterfactuals? -->
Several approaches to causal inference and counterfactuals exist, but two are particularly prominent: the potential outcomes approach, also known as the Neyman-Rubin causal model [@Neyman_et_al_1923; @Rubin_1974], and the structural approach [@Wright_1921; @Pearl_2009; @Pearl_et_al_2016]. Both approaches employ rigorous mathematical notation to characterize causal inference, but they do so in different ways [@Neal_2020]. The potential outcomes approach relies on counterfactual notation, whereas the structural approach employs the do-operator and structural causal models [SCM, @Pearl_2009; @Pearl_et_al_2016]. Despite these differences, both notations can be expressed in terms of the other, and both approaches provide methods for using experimental and observational data to estimate causal effects [@Pearl_2010]. 

<!-- 4. But which approach are we going to use? -->
Nevertheless, the structural approach offers an additional key advantage over the potential outcomes approach: it enables the graphical representation of any system through directed acyclic graphs [DAG, @Gross_et_al_2018; @Neal_2020]. DAGs are heuristics that can effectively convey the assumed causal structure of a system. They do not represent detailed statistical models but allow researchers to deduce which statistical models can provide valid causal inferences, assuming the causal structure depicted in the DAG is accurate [@McElreath_2020].

<!-- A Directed Acyclic Graph (DAG) allows for the transparent depiction of a system’s complexity, revealing its underlying assumptions and the plausible mechanisms generating the system’s outcome, assuming the DAG is true.  -->

## Directed acyclic graphs (DAG) {#sec-framework-dag}

<!-- 1. Graph theory and the use of graphs -->
Graph theory is a branch of mathematics focused on the study of graphs. Graphs are mathematical structures modeling pairwise relations between objects. They can represent physical relations, such as electrical circuits and roadways, and less tangible structures, such as ecosystems and sociological relations. Graphs have proven useful in various fields, including computer science, operations research, and the natural and social sciences [@Gross_et_al_2018].

<!-- 2. How graphs are use in the structural approach? and what are DAGs? -->
In statistics, one application incorporating concepts from graph theory is causal inference. Specifically, the structural approach to causal inference uses directed acyclic graphs (DAG) to provide a formal and graphical representation of the causal structure of a system [@Neal_2020]. In this context, a *graph* is a collection of nodes connected by edges, where nodes represent random variables. The term *directed* indicates that the edges of the graph extend from one node to another, with arrows showing the direction of causal influence. Moreover, the term *acyclic* indicates the causal influences do not form a loop, meaning the influences do not cycle back on themselves [@McElreath_2020].

<!-- 3. How do we draw DAGs? and what are the building blocks of DAGs? -->
One key advantage of DAGs is that, regardless of complexity, they can represent various causal structures using only five fundamental building blocks [@Neal_2020; @McElreath_2020]. @fig-dags illustrates these blocks. @fig-dag_bb1 depicts two unconnected nodes, representing an scenario where variables $X_{1}$ and $X_{2}$ are not causally related. @fig-dag_bb2 shows two connected nodes, illustrating a scenario where a parent node $X_{1}$ exerts a causal influence on a child node $X_{2}$. Consequently, $X_{2}$ is considered a *descendant* of $X_{1}$. @fig-dag_bb3 depicts a *chain* (or *pipe*), where $X_{1}$ influences $X_{2}$, and $X_{2}$ influences $X_{3}$. In this configuration, $X_{1}$ is a parent node of $X_{2}$, and $X_{2}$ a parent node of $X_{3}$. Furthermore, the DAG shows that $X_{1}$ is an *ancestor* of $X_{3}$ and that the relationship between these variables is entirely *mediated* by $X_{2}$. @fig-dag_bb4 illustrates a *fork*, where variables $X_{1}$ and $X_{3}$ are both influenced by $X_{2}$. In this scenario $X_{2}$ is a parent node of both $X_{1}$ and $X_{3}$. Finally, @fig-dag_bb5 depicts a *collider*, also known as *inmorality*, where variables $X_{1}$ and $X_{3}$ are concurrent causes of $X_{2}$. In this configuration, $X_{1}$ and $X_{3}$ are not causally related to each other but both influence $X_{2}$. 

::: {#fig-dags layout="[[1,1],[1,1,1]]"}

![Two unconnected nodes](images/figures/dag_bb1.png){#fig-dag_bb1 fig-align="center" width=40%}

![Two connected nodes or descendant](images/figures/dag_bb2.png){#fig-dag_bb2 fig-align="center" width=40%}

![Chain or pipe](images/figures/dag_bb3.png){#fig-dag_bb3 fig-align="center" width=100%}

![Fork](images/figures/dag_bb4.png){#fig-dag_bb4 fig-align="center" width=100%}

![Collider or inmorality](images/figures/dag_bb5.png){#fig-dag_bb5 fig-align="center" width=100%}

DAG's fundamental building blocks.
:::

<!-- 4. A motivating example -->
Given the heuristic nature of DAGs, a motivating example can help illustrate the use of the five fundamental building blocks to construct a system's causal structure. This example can also help to clarify additional conventions for drawing DAGs.

Consider a research problem where the causal effect of a variable $T$ on an outcome $Y$ needs to be investigated. Additionally, the problem suggests that a variable $X$ potentially influences both $T$ and $Y$. Such scenarios are not hard to imagine. For instance, $T$ might represent different treatments that could affect the recovery from cancer $Y$, while $X$ could denote the patient's age. Similarly, in the context of a DCJ study like the one described by @Boonen_et_al_2020, $T$ could represent the duration of a child's cochlear implant use, which might influence the child's overall speech quality $Y$, with $X$ indicating the child's hearing status. Note that these descriptions do not specify the type of data or the functional forms of the variables, highlighting the heuristic nature of DAGs. [(not a bad example, but I prefer one using writing skills)]{style="color:blue;"}

<!-- 5. DAG for the motivating example -->
@fig-example presents two graphs illustrating the plausible causal structure of the motivating example. @fig-dag_example1 shows the *simplified* DAG. In this graph, the variables of interest or *endogenous* variables $V=\{T,X,Y\}$ are depicted as solid black circles, indicating that they are observed variables. The arrows in the graph reflect the expected direction of causal influences among the variables. @fig-dag_example2, in contrast, depicts the *magnified* version of the DAG. This graph includes, in addition to the endogenous variables, the *exogenous* variables $E=\{e_{T},e_{X},e_{Y}\}$. These exogenous variables are commonly referred to as *disturbances* or *errors*, because they represent factors not explicitly modeled. They are depicted as open circles, indicating their unobserved nature. While such exogenous variables are often omitted for simplicity, including them in the graph can be advantageous in certain scenarios, as they can help to highlight potential issues related to conditioning and confounding [@Cinelli_et_al_2020], concepts that will be discussed in the next section.

<!-- 6. But where are the building blocks? -->
<!-- commands for d-separation -->
\newcommand{\dsep}{\perp\!\!\!\perp}
\newcommand{\ndsep}{\not\!\perp\!\!\!\perp}

Furthermore, a detailed examination of both figures reveals the presence of at least four of the five fundamental building blocks. @fig-dag_example1 displays multiple descendants, evident in pairwise relations such as $X \rightarrow T$, $X \rightarrow Y$, and $T \rightarrow Y$. It also illustrates a fork with $X \rightarrow \{T,Y\}$. Similarly, @fig-dag_example2 features multiple two-unconnected nodes, evident in the pairwise relations $\{e_{T} \dsep e_{X}\}$, $\{e_{T} \dsep e_{Y}\}$, and $\{e_{X} \dsep e_{Y}\}$, as well as colliders such as $\{X,e_{T}\} \rightarrow T$ and $\{X,T,e_{Y}\} \rightarrow Y$. The symbol $\dsep$ denotes a concept know as *d-separation*, which roughly implies the independence of the variables. This concept will be introduced in the next section.

::: {#fig-example layout-ncol=2}

![Simplied DAG](images/figures/dag_example1.png){#fig-dag_example1 fig-align="center" width=45%}

![Magnified DAG](images/figures/dag_example2.png){#fig-dag_example2 fig-align="center" width=85%}

DAGs for a plausible causal structure in a system.
:::


## The flow of association and causation in graphs {#sec-framework-flow}


<!-- 2. What does a DAG imply? -->
<!-- Structural Causal Model (SCM) -->
<!-- Causal models are mathematical models representing causal relationships within an individual system or population. They facilitate inferences about causal relationships from statistical data. They can teach us a good deal about the epistemology of causation, and about the relationship between causation and probability. They have also been applied to topics of interest to philosophers, such as the logic of counterfactuals, decision theory, and the analysis of actual causation. -->

<!-- (Structural Causal Model (SCM)) A structural causal model is a tuple of the following sets: -->
<!-- 1. A set ofendogenous variables 푉 2. A set ofexogenous variables 푈 3. A set of functions 푓, one to generate each endogenous variable as a function ofother variables Neal -->

<!-- \begin{aligned} -->
<!--     Y & := \; f_{Y}( X,Z,e_{Y} ) \\ -->
<!--     X & := \; f_{X}( e_{X} ) \\ -->
<!--     Z & := \; f_{Z}( e_{Z} ) \\ -->
<!--     e_{X} & \dsep e_{Z} \\ -->
<!--     e_{X} & \dsep e_{Y} \\ -->
<!--     e_{Z} & \dsep e_{Y} -->
<!-- \end{aligned}  -->

<!-- these are non-parametrical structural equations -->

<!-- Causal mechanism as a result of markov and minimality assumption -->
<!-- Modularity assumption also -->


<!-- 3. But what are those mysterious functions?, and how do they become statistical quantities? -->
![ The flow of association and causation in graphs. Extracted from @Neal_2020 [pp. 31] ](images/figures/ACflow.png){#fig-ACflow fig-align="center" width=100%}


<!-- 4. What is the local markov assumption? and where does it lead? -->
<!-- 4.1 Bayesian factorization -->

<!-- 5. What is the minimality assumption? and where does it lead? -->

<!-- 6. What is the causal edges assumption? and where does it lead? -->

<!-- 7. putting it all together -->

<!-- 9. dependence and independence in building blocks -->

<!-- 9.1 Blocked path definition-->

<!-- 9.2 d-separation -->

<!-- This further implies that to understand the causal assumptions of a complex system, one can decompose the structure into these basic building blocks and analyze the causal assumptions associated with each block individually [@McElreath_2020]. -->

<!-- Ultimately, DAGs play the important role of identifying which variables should be controlled for to be able to estimate causal effects. -->

<!-- Mention convenient R package daggitty to draw dags and extract the causal assumption inherent in a graph -->


<!-- After detailing how to build graphs and what they imply, Include steps to draw dags using a motivating example -->

<!-- point out that the disturbances are usually stochastic in nature -->


## But where does it all fit? {#sec-background-where}

<!-- The previous chapter gives graphical intuition for causal models, but it doesn’t explain how to identify causal quantities and formalize causal models. Neal -->

<!-- 4. But how do we move from targets of inference to estimates -->
<!-- But how can we move from heuristics and vague mathematic notation, to probabilistic causal analysis. -->


<!-- Before tackling the main objective of this study, however, it is important to understand how researchers can move from causal estimands to statistical estimates. Causal estimands, also known as targets of inference, are the quantities that the researcher wants to estimate. Usually, these quantities are articulated through different research questions and they are depicted using the language of the Potential Outcomes framework, Neyman-Rubin causal framework [@Neyman_et_al_1990; @Rubin_1974] mathematical expectation, e.g., $E[Y_{i}(1) - Y_{i}(0)]$ indicating that a researcher is interested in estimating the *average treatment effect* (ATE) -->

<!-- This study uses the Identification-Estimation flowchart [@McElreath_2020; @Neal_2020]. The flowchart illustrates the process of moving from a target (causal) *estimand* to a corresponding *estimate*, through identification and estimation (@fig-IEflowchart).  -->

<!-- Initially, it defines the different targets of inference (i.e., the *estimands*), which form the basis for evaluating the reliability of the DCJ method. The targets  Subsequently, the research constructs a *scientific model* for the DCJ procedure, elucidating the causal assumptions and mechanisms underlying the system, aiding in drawing inferences about causal relationships from DCJ data. Next, the study translates the scientific model into a probabilistic statistical model (i.e., an *estimator*) to derive a *statistical estimand* for the various inference targets. Bayesian statistical methods offer an intuitive approach for the task. Finally, employing multiple simulated datasets for different combinations of the relevant assessment factors, the study generates multiple *estimates* or approximations for the statistical estimands. Notably, the statistical estimands in simulated data are known, enabling the study to assess the reliability of DCJ by evaluating the *proximity* of these estimands to the generated estimates, resembling a power analysis. -->


<!-- In this context, identification refers to the process of moving from a (causal) *estimand* to an equivalent *statistical estimand*, and estimation refers to the process of moving from a *statistical estimand* to an *estimate*. -->

![ Identification-Estimation flowchart. Extracted from @Neal_2020 [pp. 32] ](images/figures/IEflow.png){#fig-IEflow fig-align="center" width=40%}


<!-- Ardmed with dags and scm, and theit probabilité implication, we can now expand on thé motivating example provided in section xx -->




# Theory {#sec-theory}

## A scientific model for the DCJ {#sec-theory-scientific}


<!-- A *scientific (causal) model* describe the causal assumptions and mechanisms underlying a system, and facilitate inferences about causal relationships from data [@Hitchcock_2023]. -->

<!-- From Lawson (2015), another way to see DCJ experiments I'd that you are grouping heterogeneous experimental units (objects) into homogeneous ones (subjects), which are your "blocks" -->


![ DCJ causal diagram, simplified description ](images/figures/SciModel_simp1.png){#fig-SciModel_simp1 fig-align="center" width=80%}

![ DCJ causal diagram, simplified mathematical description ](images/figures/SciModel_simp2.png){#fig-SciModel_simp2 fig-align="center" width=70%}

![ DCJ causal diagram, population mathematical description ](images/figures/SciModel_pop.png){#fig-SciModel_pop fig-align="center" width=70%}

<!-- check the directionality of the arrow from $p_{I}$ to $\sigma_{i(g)}$ and equivalents -->


![ DCJ causal diagram, sample with comparisons mathematical description ](images/figures/SciModel_samp.png){#fig-SciModel_samp fig-align="center" width=80%}


<!-- It is more likely that we can decide the characteristics of the objects we want to include in the study (independent variables), ensuring groups that are more balanced. However, in the case of subjects sometimes the independent variables cannot be assigned (e.g., hearing status) -->


## Probabilitics assumptions of the scientific model {#sec-theory-probability}

<!-- what does it mean in probabilistic terms? describe probabilities and arrive to structural model -->


<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} := & \; f_{O}( \delta_{kijr_{ij}} ) \\ -->
<!--   \delta_{kijr_{ij}} := & \; f_{D}( \gamma_{k}, \theta_{ir_{i}} ) \\ -->
<!--   \gamma_{k} := & \; f_{G}( Z_{k}, e_{k} ) \\ -->
<!--   \theta_{ir_{i}} := & \; f_{R}( \theta_{i}, Y_{r}, e_{r_{i}} ) \\ -->
<!--   \theta_{i} := & \; f_{T}( X_{i}, e_{i} ) \\ -->
<!--   & \; e_{k} \dsep e_{i} \\ -->
<!--   & \; e_{k} \dsep e_{r_{i}} \\ -->
<!--   & \; e_{i} \dsep e_{r_{i}} -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StructuralModel} -->



## From the scientific to statistical model {#sec-theory-statistics}

<!-- "An appropriate analysis of data cannot be completed without knowledge of what experimental design was used and how the data was collected, and conclusions are not reliable if they are not justified by the proper modeling and analysis of the data" (Lawson, 2015, p. 7) -->

<!-- "In many cases where observational units are different than the experimental units, the observational units will not be independent" (p. 177) -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} \sim & \; \text{Bernoulli}\left[ \; logit^{-1}\left( \delta_{kijr_{ij}} \right) \; \right] \\ -->
<!--   \delta_{kijr_{ij}} = & \; \gamma_{k}( \theta_{ir_{i}} - \theta_{jr_{j}} ) \\ -->
<!--   \gamma_{k} = & \; logit^{-1}\left[ \beta_{Z} Z_{k} + e_{k} \right] \\ -->
<!--   \theta_{ir_{i}} = & \; \theta_{i} + \beta_{Y} Y_{r} + e_{r_{i}}  \\ -->
<!--   \theta_{i} = & \; \beta_{X} X_{i} + e_{i}  \\ -->
<!--   e_{k} \sim & \; \text{Normal}(0, \sigma_{k(g)}) \\ -->
<!--   e_{i} \sim & \; \text{Normal}(0, \sigma_{i(g)}) \\ -->
<!--   e_{r_{i}} \sim & \; \text{Normal}(0, \sigma_{r(g)}) -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StatModel_general} -->

<!-- for identification purposes we can set $\frac{1}{G}\sum_{g=1}^{G} \sigma_{k(g)} = 0.02$, $\frac{1}{G}\sum_{g=1}^{G} \sigma_{i(g)} = 1$, and $\frac{1}{G}\sum_{g=1}^{G} \sigma_{r(g)} = 1$. A special case of this would be to assume that the data comes from the same population, in that case, $\sigma_{k(g)} = \sigma_{k} = 0.02$, $\sigma_{i(g)} = \sigma_{i} = 1$ -->




## Let's talk about Thurstone {#sec-theory-thurstone}


<!-- Thurstone's comparative judgment @Thurstone_1927 is based on the formula: -->
<!-- $$ -->
<!-- X_{AB} = \frac{S_{A} - S_{B}}{\sigma_{AB}} -->
<!-- $$ -->

<!-- where $X_{AB}$ defines the comparative judgment outcome, $S_{A}$ and $S_{B}$ are the modal discriminal processes, $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B} + 2 \rho \sigma_{A} \sigma_{B}}$, with $\sigma_{A}$ and $\sigma_{B}$ being the dispersion of discriminal processes $A$ and $B$, respectively, and $\rho$ the correlation between discriminal processes.    -->

<!-- The theory identifies five cases: -->

<!-- - **Case 1:** only constant $\rho$ (not $\rho_{ij}$) -->
<!-- - **Case 2:** $X_{ij}$ becomes $X_{kij}$ with $k=1, \dots, K$ judges (replication, not duplication) -->
<!-- - **Case 3:** $\rho = 0$, then $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B}}$  -->
<!-- - **Case 4:** $\sigma_{B}=\sigma_{A}+d$, then $\lim_{d \leq 0.1\sigma_{A}} \sigma_{AB} = (\sigma_{A} + \sigma_{B}) /\sqrt{2}$ -->
<!-- - **Case 5:** $\sigma_{B}=\sigma_{A}$, then $\sigma_{AB} = \sqrt{2}\sigma$ -->

<!-- Now using the DAG and statistical notation -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} := & \; f_{O}( \delta_{kijr_{ij}} ) \\ -->
<!--   \delta_{kijr_{ij}} = & \; \gamma_{k}( \theta_{ir_{i}} - \theta_{jr_{j}} ) \\ -->
<!--   \gamma_{k} = & \; f_{G}( Z_{k}, e_{k} ) \\ -->
<!--   \theta_{ir_{i}} = & \; \theta_{i} + \beta_{Y} Y_{r} + e_{r_{i}}  \\ -->
<!--   \theta_{i} = & \; \beta_{X} X_{i} + e_{i}  \\ -->
<!--   e_{k} \sim & \; \text{Normal}(0, \sigma_{k(g)}) \\ -->
<!--   e_{i} \sim & \; \text{Normal}(0, \sigma_{i(g)}) \\ -->
<!--   e_{r_{i}} \sim & \; \text{Normal}(0, \sigma_{r(g)}) -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StatModel_thurstone} -->

<!-- The theory identifies five cases: -->

<!-- - **Case 1:** only constant $\rho \approx \sigma_{i}$ -->
<!-- - **Case 2:** now judges are separated by using $\gamma_{k}$ -->
<!-- - **Case 3:** $\rho \approx \sigma_{e_{i}} = 0$ (no nesting of texts on students), then $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B}}$  -->
<!-- - **Case 4:** $\sigma_{B}=\sigma_{A}+d$, then $\lim_{d \leq 0.1\sigma_{A}} \sigma_{AB} = (\sigma_{A} + \sigma_{B}) /\sqrt{2}$ -->
<!-- - **Case 5:** $\sigma_{B}=\sigma_{A}$, then $\sigma_{AB} = \sqrt{2}\sigma$ -->

<!-- But now can we see other scenarios than just those 5 cases? -->

<!-- - consider different $\rho \approx \sum_{p=1}^{P} \sigma_{p}$, depending on $P$ nesting structures  -->
<!-- - we can now investigate $\gamma_{k}$ -->
<!-- - we can assume $\sigma_{B} \neq \sigma_{A}$, no need for results on the limit -->


# Discussion {#sec-discuss}

## Findings {#sec-discuss-finding}

<!-- no fundamental ontological objections to using DAGs to describe causal models and causal relationships. -->

## Limitations and further research {#sec-discuss-limitations}
<!-- and most of the methods depend on unverifiable assumptions, causal inference can still identify causes and estimate their effects, assuming a set of plausibles mechanisms for a system. -->



# Conclusion {#sec-conclusion}



{{< pagebreak >}}

# Declarations {.appendix .unnumbered}

**Funding:** The project was founded through the Research Fund of the University of Antwerp (BOF).

**Financial interests:** The authors have no relevant financial interest to disclose.

**Non-financial interests:** Author XX serve on advisory broad of Company Y but receives no compensation this role.

**Ethics approval:** The University of Antwerp Research Ethics Committee has confirmed that no ethical approval is required.

**Consent to participate:** Not applicable

**Consent for publication:** All authors have read and agreed to the published version of the manuscript.

**Availability of data and materials:** No data was utilized in this study.

**Code availability:** All the code utilized in this research is available in the digital document located at: [https://jriveraespejo.github.io/paper2_manuscript/](https://jriveraespejo.github.io/paper2_manuscript/).  

**Authors' contributions:** *Conceptualization:* S.G., S.DM., T.vD., and J.M.R.E; *Methodology:* S.DM., T.vD., and J.M.R.E; *Software:* J.M.R.E.; *Validation:* J.M.R.E.; *Formal Analysis:* J.M.R.E.; *Investigation:* J.M.R.E; *Resources:* S.G., S.DM., and T.vD.; *Data curation:* J.M.R.E.; *Writing - original draft:* J.M.R.E.; *Writing - review & editing:* S.G., S.DM., and T.vD.; *Visualization:* J.M.R.E.; *Supervision:* S.G. and S.DM.; *Project administration:* S.G. and S.DM.; *Funding acquisition:* S.G. and S.DM.

<!-- **Acknowledgements:** NO additional acknowledgements -->



{{< pagebreak >}}

# Appendix {#sec-appendix}

## Why do we need to estimate judges' abilities? {#sec-appA}

<!-- The same idea as interactions: when interactions are significant, the interpretations of the parameters cannot be made in isolation -->

## Latent variables as a mean of imputation {#sec-appB}

<!-- Latent variables and random effects are in essence imputation? (McElreath, p. 504) -->
<!-- Judge index works as a descendant of the latent variables, or the latent variable is not a reflective, but generative where the index is multiplied by a loading? -->
<!-- see Morgan et al (2014) -->
<!-- see Mayer (2019) -->

## Other comparative scenarios  {#sec-appC}

{{< pagebreak >}}

## References {.unnumbered}

:::{#refs}

:::