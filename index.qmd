---
title: "Causes and effects in Dichotomous Comparative Judgments: an information-theoretical system of plausible mechanism"
author:
  - name: 
      given: Jose Manuel
      family: Rivera Espejo
    orcid: 0000-0002-3088-2783
    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/
    email: JoseManuel.RiveraEspejo@uantwerpen.be
    corresponding: true
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: lead
      - methodology: lead
      - software: only
      - validation: only
      - formal analysis: only
      - investigation: only
      - resources: no
      - data curation: only
      - writing: only
      - editing: no
      - visualization: only
      - supervision: no
      - project administration: no
      - funding adquisition: no
  - name: 
      given: Tine
      family: van Daal
      non-dropping-particle: van
    orcid: https://orcid.org/0000-0001-9398-9775
    url: https://www.uantwerpen.be/en/staff/tine-vandaal/
    email: tine.vandaal@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: support
      - methodology: support
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: no
      - project administration: no
      - funding adquisition: no
  - name: 
      given: Sven
      family: De Maeyer
      non-dropping-particle: De
    orcid: 0000-0003-2888-1631
    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/
    email: sven.demaeyer@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: support
      - methodology: support
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: yes
      - project administration: yes
      - funding adquisition: yes
  - name: 
      given: Steven
      family: Gillis
    orcid: 
    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/
    email: steven.gillis@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Linguistics
        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)
    roles: 
      - conceptualization: support
      - methodology: no
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: yes
      - project administration: yes
      - funding adquisition: yes
funding: 
  statement: "The project was founded through the Research Fund of the University of Antwerp (BOF)."
keywords:
  - causal inference
  - probability
  - Thurstone
  - comparative judgement
  - directed acyclic graph
  - structural causal models
  - statistical modeling
abstract: |
  Dichotomous Comparative Judgment (DCJ) requires judges to compare pairs of stimuli to determine which one exhibits a higher degree of a specific trait. DCJ has proven effective and reliable across various fields [@Pollitt_2012b; @Jones_2015; @vanDaal_et_al_2016; @Bartholomew_et_al_2018; @Lesterhuis_2018; @Bartholomew_et_al_2020; @Marshall_et_al_2020; @Boonen_et_al_2020]. However, despite the method's widespread use, existing literature lacks a clear explanation of the complexities and assumptions underpinning the DCJ system, as well as the plausible mechanisms through which DCJ data could be generated. This study addresses these issues by representing DCJ within the framework of causal inference. Specifically, utilizing the structural approach, the study develops a scientific model to clarify plausible causal assumptions and mechanisms inherent in the DCJ system. The study then translates this model into a probabilistic statistical model to estimate statistical relationships and infer causal effects within the system. This research provides a robust probabilistic foundation for the statistical analysis of DCJ data, building upon Thurstone’s law of comparative judgment [-@Thurstone_1927]. Its findings offer valuable insights for researchers and analysts designing and implementing DCJ experiments.
key-points:
  - (to do)
date: last-modified
bibliography: references.bib
notebook-links: global
lightbox: true
citation: true
  # type: article-journal
  # container-title: "Psychometrika"
  # doi: ""
  # # url: https://example.com/summarizing-output
execute: 
  cache: true
  # eval: true
  echo: false
  # output: true
  # include: true
  warning: false
  error: false
  message: false
---

# Introduction {#sec-introduction}

<!-- 1. What is comparative judgment? -->
In contemporary contexts, Thurstone's law of comparative judgment [-@Thurstone_1927] primarily refers to the method of *dichotomous* comparative judgment [DCJ, @Pollitt_2012a; @Pollitt_2012b]. In DCJ, a judge assesses the relative manifestation of a *trait* within a pair of stimuli. This assessment results in a dichotomous value indicating which stimulus possesses a higher degree of the trait. After different judges perform multiple rounds of pairwise comparisons, an outcome vector is produced. This vector is modeled using the Bradley-Terry-Luce model [BTL, @Bradley_et_al_1952; @Luce_1959], which creates a score that corresponds with the trait of interest. This score is then used to rank the stimuli from lowest to highest or to evaluate the influence of certain variables on the stimuli's positions in the ranking.

<!-- 2. in what has been applied on?, and where is the gap? -->
DCJ has proven effective in assessing competencies and traits predominantly within the educational realm, as demonstrated by @Pollitt_2012b, @Jones_2015, @vanDaal_et_al_2016, @Bartholomew_et_al_2018, @Lesterhuis_2018, @Bartholomew_et_al_2020, and @Marshall_et_al_2020. However, its application transcends education, as exemplified by @Boonen_et_al_2020. The methodology has also evolved to include multiple, as opposed to pairwise comparisons [@Luce_1959; @Placket_1975], and to accommodate comparisons with ordinal outcomes [@Tutz_1986; @Agresti_1992]. Overall, research suggests that DCJ offers an alternative and efficient approach to measurement and evaluation, characterized by its reliability and validity [@Lesterhuis_2018; @vanDaal_2020; @Marshall_et_al_2020; @Bouwer_et_al_2023]. Nevertheless, despite the method's widespread use, existing literature lacks a clear representation of the plausible mechanisms through which DCJ data could be generated. Particularly, there is no depiction of the complexity and the assumptions underpinning the DCJ system, nor how different assessment factors can potentially influence the observed DCJ outcome.

<!-- 3. What are the factors behind DCJ? -->
According to @Verhavert_et_al_2019 and @vanDaal_2020, several assessment factors interact and influence the method's outcome. These factors include the number and characteristics of the stimuli, their *proximity* in terms of the assessed trait, the number of comparison per stimulus, and the pairing algorithm used. Furthermore, since the method relies on judges' assessments, the number and characteristics of judges, their *discrimination* abilities, and the number of comparisons per judge also play pivotal roles. Moreover, when the stimuli represent sub-units of higher-levels units, factors such as the number and characteristics of these units, along with their *proximity* in terms of the assessed trait, can significantly influence the outcome. For example, in @vanDaal_et_al_2016, the authors assessed the academic writing skills of university students (units) using multiple argumentative essays (sub-units).

<!-- 4. Solution to the gap -->
Although several studies have examined the individual impact of these factors on the method's reliability [@Bramley_2015; @Pollitt_2012b; @Bramley_et_al_2019; @Verhavert_et_al_2019; @Crompvoets_et_al_2022; @vanDaal_et_al_2017; @Gijsen_et_al_2021; @Bouwer_et_al_2023], none, to the best of the authors' knowledge, have provided a transparent depiction of the DCJ system and the mechanisms generating the DCJ outcome. This study aims to fill this gap by representing DCJ within the framework of causal inference. Specifically, utilizing the structural approach to causal inference, the study develops a scientific model to clarify plausible causal assumptions and mechanisms inherent in the DCJ system. The study then translates the scientific model into a probabilistic statistical model. This model aims to produce statistical estimates to draw inferences about plausible causal relationships within the DCJ system. 

<!-- 5. final objective and relevance -->
Ultimately, this study provides a robust causal and probabilistic foundation for the statistical analysis of DCJ data, building upon Thurstone’s law of comparative judgment [-@Thurstone_1927]. Consequently, its findings offer valuable insights for researchers and analysts designing and implementing DCJ experiments.


# Theoretical framework {#sec-framework}

This section introduces fundamental concepts in causal inference but does not offer a comprehensive description of causal inference methods. Readers interested in deeper exploration should consult introductory papers like @Pearl_2010, @Rohrer_2018, @Pearl_2019, and @Cinelli_et_al_2020. They may also find introductory books such as @Pearl_et_al_2018, @Neal_2020 and @McElreath_2020 useful. For more advanced study, seminal intermediate papers like @Neyman_et_al_1923, @Rubin_1974, @Spirtes_et_al_1991, and @Sekhon_2009, as well as books like @Pearl_2009, @Morgan_et_al_2014 and @Hernan_et_al_2020 are recommended.


## The structural approach to causal inference {#sec-framework-structural}

<!-- 1. What does empirical research do first? -->
Empirical research addresses real-world challenges by relying on evidence gathered through observation and experimentation. In this context, researchers typically frame their research questions as *estimands* or *targets of inference*. These estimands represent the specific quantities the study aims to determine [@Everitt_et_al_2010]. For instance, a study might examine the question, “To what extent do different teaching methods ($T$) influence students’ conceptual understanding of a topic ($Y$)?" To investigate this, the study could randomly assign students to two groups, each using a different teaching method $(T_{i}=\{1,2\})$. Students’ conceptual understanding of the topic could be evaluated through pairwise comparisons, resulting in a dichotomous outcome $(Y_{i}=\{0,1\})$, indicating which student among those compared has a higher level of understanding. The research question could be then framed as the estimand, “*On average*, is there a difference in conceptual understanding of the topic between the two groups of students?” This estimand could be mathematically expressed by the associational quantity $E[Y_{i}| T_{i}=1] - E[Y_{i}| T_{i}=2]$, where $E[\cdot]$ denotes the expected value. An example of this approach is seen in @Jones_et_al_2019.

<!-- 2. What do they do next? -->
Researchers then proceed to identify the estimands. *Identification* refers to the process of accurately computing an estimand using an estimator. An *estimator* is a method or function that maps data into an estimate [@Neal_2020]. *Estimates* are numerical values that approximate the estimand and are derived through *estimation*, which refer to the process of integrating data with an estimator [@Everitt_et_al_2010]. Although various methods can approximate an estimand, researchers prioritize estimators with desirable properties that ensure the accuracy of estimates. For instance, the BTL model [@Bradley_et_al_1952; @Luce_1959] is an estimator known for its effectiveness in modeling pairwise comparisons, yielding accurate estimates for the target of inference discussed earlier, as long as the assumptions of the model are met.

<!-- 3. But we want these estimands to be causal -->
However, many studies aim to understand the mechanisms underlying specific data types and also seek to establish causal relationships rather than merely infer associations. In the earlier example, the differences between groups obtained using the BTL model, referred to as the associational estimates, can be interpreted as causal because the data were collected through a randomized experiment. Randomized experiments enable the causal interpretation of associational estimates by ensuring several key properties, including common support, no interference, and consistency [@Morgan_et_al_2014; @Neal_2020]. The most crucial property, however, is that randomization effectively eliminates confounding. *Confounding* occurs when an external variable influences both the outcome and the variable of interest, leading to spurious associations [@Everitt_et_al_2010]. Randomization mitigates this issue by decoupling the intervention assignment mechanism, such as assigning students to different groups, from other variables and outcomes [@Morgan_et_al_2014; @Neal_2020].

<!-- 4. Experiments are not available to everyone, then causal inference comes to the rescue -->
Experiments are widely regarded as the gold standard in evidence-based science [@Hariton_et_al_2018; @Hansson_2014], however, researchers often encounter constraints that limit their ability to conduct experimental studies. These constraints include ethical concerns, such as the assignment of individuals to potentially harmful interventions, and practical limitations, such as the infeasibility of, for example, assigning individuals to genetic modifications or physical impairments [@Neal_2020]. In these instances, causal inference offers a valuable alternative for generating causal estimates. *Causal inference* is a framework designed to identify the causes of phenomena and estimate their effects using data [@Shaughnessy_et_al_2010; @Neal_2020]. Unlike classical statistical modeling, which focuses primarily on summarizing data and inferring associations, causal inference provides a rigorous mathematical framework for analyzing causes and counterfactuals [@Pearl_2009]. Consequently, the framework offers significant theoretical insights that enhance the design of observational and experimental studies [@McElreath_2020].

<!-- 6. But how does it work? -->
While a detailed explanation of causes and counterfactuals is beyond the scope of this document, it is important to note that causal inference addresses the *fundamental problem of causality* through the use of counterfactuals [@Neal_2020]. The framework defines *individual causal effects* (ICE) as the difference between an individual's observed and unobserved potential outcomes. These unobserved potential outcomes, known as *counterfactuals*, represent hypothetical scenarios that are *contrary to fact*, where alternative outcomes for an individual, resulting from a specific cause, are neither observed nor observable [@Neal_2020; @Counterfactual_2024]. The framework then extends this estimand to *average causal effects* (ACE), which captures the difference between sample averages of observed potential outcomes and counterfactuals. Finally, much like in an experiment, the framework identifies the ACE from associational estimates by conditioning for a *sufficient adjustment set* of variables, ensuring the absence of confounding [@Morgan_et_al_2014].

<!-- 7. How do we apply causal inference and counterfactuals? -->
Several approaches to causal inference and counterfactuals exist, but two are particularly prominent: the potential outcomes approach, also known as the Neyman-Rubin causal model [@Neyman_et_al_1923; @Rubin_1974], and the structural approach [@Pearl_2009; @Pearl_et_al_2016]. Both approaches employ rigorous mathematical notation to characterize the ACE, but they do so in different ways [@Neal_2020]. The potential outcomes approach relies on counterfactual notation, whereas the structural approach employs do-calculus [@Pearl_2009]. Despite these differences, both notations can be expressed in terms of the other, and both approaches provide methods for using experimental and observational data to estimate causal effects [@Pearl_2010].

<!-- 8. But which approach are we going to use? -->
The structural approach, however, offers a notable advantage over the potential outcomes approach by allowing the graphical and formal representation of theories through directed acyclic graphs [DAG, @Pearl_2009; @Pearl_et_al_2016; @Gross_et_al_2018; @Neal_2020]. DAGs function as heuristics, effectively conveying the presumed causal structure of a system, referred to as a *scientific model*. They do not represent detailed statistical models but allow researchers to deduce which statistical models can provide valid causal inferences, assuming the causal structure depicted in the DAGs are accurate [@McElreath_2020]. The Identification-Estimation flowchart in @fig-IEflow [@McElreath_2020; @Neal_2020] visually represents this process of transitioning from estimands to estimates, as well as the application of the scientific model and data to identify and estimate causal effects.

<!-- A heuristic is a strategy that simplifies information to make decisions more quickly, efficiently, and sometimes more accurately than complex methods [@Chow_2015]. -->

![ Identification-Estimation flowchart. Extracted and slightly modified from @Neal_2020 [pp. 32] ](images/figures/IEflow.png){#fig-IEflow fig-align="center" width=40%}


## DAGs and SCMs {#sec-framework-dag}

<!-- 1. Graph theory and the use of graphs -->
Graph theory is a branch of mathematics focused on the study of graphs. Graphs are mathematical structures modeling pairwise relations between objects. They can represent physical relations, such as electrical circuits and roadways, and less tangible structures, such as ecosystems and sociological relations. Graphs have proven useful in various fields, including computer science, operations research, and the natural and social sciences [@Gross_et_al_2018]. 

<!-- 2. What does the structural approach uses?, and what are DAGs? -->
In statistics, one application incorporating concepts from graph theory is causal inference. Specifically, the structural approach to causal inference uses directed acyclic graphs (DAG) to provide a graphical and formal representation of the causal structure of a system [@Neal_2020]. In this context, a *graph* denotes a collection of nodes connected by edges, where nodes represent random variables. The term *directed* indicates the edges of the graph extend from one node to another, with arrows showing the direction of causal influence. Moreover, the term *acyclic* indicates the causal influences do not form a loop, meaning the influences do not cycle back on themselves [@McElreath_2020]. 

<!-- 3. What are the advantages of DAGs? -->
DAGs offer two key advantages for modeling causal structures. Firstly, they represent causal relations in a nonparametric and fully interactive manner. This feature allows for feasible causal analysis strategies without needing the specification of the type of data or the nature of the functional dependence among variables [@Morgan_et_al_2014]. Secondly, regardless of complexity, DAGs can represent various causal structures using only five fundamental building blocks [@Neal_2020; @McElreath_2020]. This feature enables the decomposition of complex structures into basic building blocks, facilitating the analysis of these structures by focusing on the causal assumptions associated with each building block individually [@McElreath_2020]. These building blocks can be represented in three ways: the magnified representation, the standard representation, and the structural causal model form [SCM, @Morgan_et_al_2014].


<!-- commands for d-separation -->
\newcommand{\dsep}{\perp\!\!\!\perp}
\newcommand{\ndsep}{\not\!\perp\!\!\!\perp}


::: {#fig-dags_scms layout="[ [1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1] ]"}

![Two unconnected nodes](images/figures/mdag_bb1.png){#fig-mdag_bb1 fig-align="center" width=80%}

![Two unconnected nodes](images/figures/sdag_bb1.png){#fig-sdag_bb1 fig-align="center" width=35%}

::: {#fig-scm_bb1 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  Y & := f_{Y}(e_{Y}) \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

Two unconnected nodes
:::

![Two connected nodes or descendant](images/figures/mdag_bb2.png){#fig-mdag_bb2 fig-align="center" width=80%}

![Two connected nodes or descendant](images/figures/sdag_bb2.png){#fig-sdag_bb2 fig-align="center" width=35%}

::: {#fig-scm_bb2 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  Y & := f_{Y}(X,e_{Y}) \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

Two connected nodes or descendant
:::

![Chain or pipe](images/figures/mdag_bb3.png){#fig-mdag_bb3 fig-align="center" width=100%}

![Chain or pipe](images/figures/sdag_bb3.png){#fig-sdag_bb3 fig-align="center" width=55%}

::: {#fig-scm_bb3 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  Z & := f_{Z}(X,e_{Z}) \\
  Y & := f_{Y}(Z,e_{Y}) \\
  e_{X} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Z} \\
  e_{Z} & \dsep e_{Y}
\end{aligned}
$$

Chain or pipe
:::

![Fork](images/figures/mdag_bb4.png){#fig-mdag_bb4 fig-align="center" width=100%}

![Fork](images/figures/sdag_bb4.png){#fig-sdag_bb4 fig-align="center" width=55%}

::: {#fig-scm_bb4 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(Z,e_{X}) \\
  Z & := f_{Z}(e_{Z}) \\
  Y & := f_{Y}(Z,e_{Y}) \\
  e_{X} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Z} \\
  e_{Z} & \dsep e_{Y}
\end{aligned}
$$

Fork
:::

![Collider or inmorality](images/figures/mdag_bb5.png){#fig-mdag_bb5 fig-align="center" width=100%}

![Collider or inmorality](images/figures/sdag_bb5.png){#fig-sdag_bb5 fig-align="center" width=55%}

::: {#fig-scm_bb5 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  Z & := f_{Z}(X,Y,e_{Z}) \\
  Y & := f_{Y}(e_{Y}) \\
  e_{X} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Z} \\
  e_{Z} & \dsep e_{Y}
\end{aligned}
$$

Collider or inmorality
:::


The five fundamental building blocks of DAGs. **Note:** left panels show the magnified representation, middle panels show the standard representation, and the right panels show their corresponding SCM form.
:::


<!-- 3. how DAGs are depicted? -->
<!-- 3.1 the magnified DAG -->
The left panels of @fig-dags_scms illustrate the *magnified* representation. These graphs depict the *endogenous* variables $V=\{X,Z,Y\}$ alongside the *exogenous* variables $E=\{e_{X},e_{Z},e_{Y}\}$. Endogenous variables are those whose causal mechanisms the investigator chooses to model [@Neal_2020]. In contrast, exogenous variables represent *errors* or *disturbances* arising from omitted factors that the investigator chooses not to model explicitly [@Pearl_2009, pp. 27,68]. The graphs show endogenous variables as solid black circles to signify that they are observed random variables, while endogenous variables are depicted as open circles to signify their unobserved (latent) nature. Lastly, the arrows in the graphs reflect the expected direction of causal influences among these variables.

<!-- 3.2 the simplified DAG -->
Often, DAGs omit the exogenous variables for simplicity, resulting in the *standard* representation. However, including exogenous variables in a graph can be beneficial in some scenarios, as their presence can reveal potential issues related to conditioning and confounding [@Cinelli_et_al_2020], concepts explored in @sec-framework-flow. The standard representation is illustrated in the middle panels of @fig-dags_scms.

<!-- 3.3 the SCM -->
Lastly, the right panels of @fig-dags_scms depict the SCM form of the fundamental building blocks. SCMs are formal mathematical models defined by a set of endogenous variables $V$, a set of exogenous variables $E$, and a set of functions $F=\{f_{X},f_{Z},f_{Y}\}$ [@Pearl_2009; @Neal_2020]. These functions, referred to as structural equations, specify each endogenous variable as nonparametric functions of other variables. Moreover, SCMs use the symbol '$:=$' to indicate the variables' asymmetrical causal dependence and the symbol '$\dsep$' to represent *d-separation*, which roughly equates to the concept of variable independence. The concepts of d-separation and causal (in)dependence are explored in @sec-framework-flow.

<!-- 4. But what does the building blocks mean? -->
A careful examination of @fig-dags_scms highlights the assumptions underlying these building blocks. Figures [-@fig-mdag_bb1], [-@fig-sdag_bb1], and SCM [-@fig-scm_bb1] depict two unconnected nodes, representing a scenario where variables $X$ and $Y$ are not causally related. Figures [-@fig-mdag_bb2], [-@fig-sdag_bb2], and SCM [-@fig-scm_bb2] illustrate two connected nodes, showing a scenario where a *parent* node $X$ exerts a causal influence on a *child* node $Y$. Consequently, $Y$ is considered a *descendant* of $X$. Figures [-@fig-mdag_bb3], [-@fig-sdag_bb3], and SCM [-@fig-scm_bb3] depict a *chain* or *pipe*, where $X$ influences $Z$, and $Z$ influences $Y$. In this configuration, $X$ is a parent node of $Z$, and $Z$ is a parent node of $Y$. This creates a *directed path* between $X$ and $Y$. Consequently, $X$ is an *ancestor* of $Y$, and $Z$ fully *mediates* the relationship between the two. Figures [-@fig-mdag_bb4], [-@fig-sdag_bb4], and SCM [-@fig-scm_bb4] illustrate a *fork*, where variables $X$ and $Y$ are both influenced by $Z$. Here, $Z$ is a parent node of $X$ and $Y$. Finally, Figures [-@fig-mdag_bb5], [-@fig-sdag_bb5], SCM [-@fig-scm_bb5] depict a *collider*, also known as *inmorality*, where variables $X$ and $Y$ are concurrent causes of $Z$. In this configuration, $X$ and $Y$ are not causally related to each other but both influence $Z$. Additionally, in all SCMs, the errors are assumed to be mutually independent of each other and of all other variables in the graph, as evidenced by the pairwise relations $e_{X} \dsep e_{Y}$, $e_{X} \dsep e_{Z}$, and $e_{Z} \dsep e_{Y}$.

<!-- 5. continuing with the motivating example -->
The motivating example in @sec-framework-structural can further illustrate how to use the five fundamental building blocks to construct a system's causal structure. In this scenario, the investigator aims to determine whether, *on average*, there is a difference in conceptual understanding of a topic $(Y_{i}=\{0,1\})$ between two groups of students $(T_{i}=\{1,2\})$, described by the estimand $E[Y_{i}| T_{i}=1] - E[Y_{i}| T_{i}=2]$. However, unlike the previous case, an experiment cannot be conducted, and the problem suggests that the country to which a student belongs ($X$) may influence both $T$ and $Y$. Such scenarios are plausible, especially when the teaching methods depend on software or access to technology, which may be limited in certain countries [(maybe an example with more impact?)]{style="color:blue;"}. @fig-example illustrates the plausible causal structure of the motivating example. A detailed examination of Figures [-@fig-mdag_example1], [-@fig-sdag_example1], and SCM [-@fig-scm_example1] reveals the presence of at least four of the five fundamental building blocks. The figures display multiple descendants, as indicated by pairwise relations such as $X \rightarrow T$, $X \rightarrow Y$, and $T \rightarrow Y$. Additionally, the figures features multiple pairs of unconnected nodes, evident from the relations $e_{T} \dsep e_{X}$, $e_{T} \dsep e_{Y}$, and $e_{X} \dsep e_{Y}$. Finally, the figures illustrate the fork $X \rightarrow \{T,Y\}$, and two colliders with $\{X,e_{T}\} \rightarrow T$ and $\{X,T,e_{Y}\} \rightarrow Y$.


::: {#fig-example layout="[ [1,1,1],[1,1,1],[1,1,1] ]"}

![Magnified representation](images/figures/mdag_example1.png){#fig-mdag_example1 fig-align="center" width=100%}

![Standard representation](images/figures/sdag_example1.png){#fig-sdag_example1 fig-align="center" width=55%}

::: {#fig-scm_example1 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  T & := f_{Z}(X,e_{T}) \\
  Y & := f_{Y}(T,X,e_{Y}) \\
  e_{T} & \dsep e_{X} \\
  e_{T} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

Structural causal model
:::

DAGs for a plausible causal structure in a system.
:::


## The flow of association and causation in graphs {#sec-framework-flow}


<!-- The main assumption we’ve seen that relates the graph to the distribution -->
<!-- is the Markov assumption. The Markov assumption tells us if variables are -->
<!-- d-separated in the graph 𝐺 , then they are independent in the distribution -->
<!-- 𝑃 (Theorem 3.1): -->
<!-- Maybe we can detect independencies in the data and then use that -->
<!-- to infer the causal graph. However, going from independencies in the -->
<!-- distribution 𝑃 to d-separations in the graph 𝐺 isn’t something that the -->
<!-- Markov assumption gives us (see Equation 3.20 above). Rather, we need -->
<!-- the converse of the Markov assumption. This is known as the faithfulness -->
<!-- assumption. -->
<!-- Assumption 11.1 (Faithfulness) -->


<!-- 1. What has been said about DAGs? -->
<!-- The previous section gives a concise graphical intuition for DAGs, sufficient to emphasize their effectiveness in encoding causal structures. However, so far, nothing has been said about how to identify causal quantities or how to formalize DAGs into probabilistic statistical models.  -->

<!-- “identification” in this book, we are referring to the process -->
<!-- of moving from a causal estimand to an equivalent statistical estimand. -->
<!-- When we say “estimation,” we are referring to the process of moving from -->
<!-- a statistical estimand to an estimate. Neal -->

<!-- The previous section gives a concise graphical intuition for DAGs, sufficient to emphasize their effectiveness in encoding causal structures. However, it doesn’t explain how to identify causal quantities and formalize causal models. Neal -->

<!-- However, the requirements to use DAGs as encoders of causal assumptions and how these can transform into probabilistic statistical models have not yet been discussed. -->

<!-- 2. What is the local markov assumption? and where does it lead? -->
<!-- 2.1 Bayesian network factorization -->

<!-- 3. What is the causal edges assumption? and where does it lead? -->

<!-- 4. Combined they are known as the minimality assumption? -->


<!-- 5. Now, what are those mysterious functions?, and how do they become statistical quantities? -->


<!-- 1. But what are the assumption that allow us to treat DAGs as causal structures -->
![ The flow of association and causation in graphs. Extracted and slightly modified from @Neal_2020 [pp. 31] ](images/figures/ACflow.png){#fig-ACflow fig-align="center" width=80%}


<!-- Another advantage of graphical models is that they allow us to express joint distributions very efficiently. -->

<!-- Second, in a fully specified SCM, we can represent the joint distributions of n variables -->
<!-- with greater efficiency: We need only to specify the n functions that govern the relationships between the variables, and then from the probabilities of the error terms, we can discover all the probabilities that govern the joint distribution. -->


<!-- 6. What is the modularity assumption? and where does it lead? -->
<!-- 6.1 the Truncated factorization -->
<!-- 6.2 The law of counterfactuals -->

<!-- 7. Causal mechanism -->
<!-- 7.3 the backdoor criterion (do you need it?) -->

<!-- 5. d-separation -->
<!-- 5.1 Blocked path definition-->



<!-- 6. putting it all together -->
<!-- 6.1. Revising the building block: dependence and independence -->


<!-- Ultimately, DAGs play the important role of identifying which variables should be controlled for to be able to estimate causal effects. -->

<!-- Mention convenient R package daggitty to draw dags and extract the causal assumption inherent in a graph -->


<!-- After detailing how to build graphs and what they imply, Include steps to draw dags using a motivating example -->

<!-- point out that the disturbances are usually stochastic in nature -->

<!-- Causal mechanism as a result of markov and minimality assumption -->
<!-- Modularity assumption also -->


<!-- 4. But how do we move from targets of inference to estimates -->
<!-- But how can we move from heuristics and vague mathematic notation, to probabilistic causal analysis. -->



<!-- Ardmed with dags and scm, and theit probabilité implication, we can now expand on thé motivating example provided in section xx -->



# Theory {#sec-theory}

## A scientific model for the DCJ {#sec-theory-scientific}


<!-- A *scientific (causal) model* describe the causal assumptions and mechanisms underlying a system, and facilitate inferences about causal relationships from data [@Hitchcock_2023]. -->

<!-- From Lawson (2015), another way to see DCJ experiments I'd that you are grouping heterogeneous experimental units (objects) into homogeneous ones (subjects), which are your "blocks" -->



![ DCJ causal diagram, simplified description ](images/figures/SciModel_simp1.png){#fig-SciModel_simp1 fig-align="center" width=80%}

![ DCJ causal diagram, simplified mathematical description ](images/figures/SciModel_simp2.png){#fig-SciModel_simp2 fig-align="center" width=70%}

![ DCJ causal diagram, population mathematical description ](images/figures/SciModel_pop.png){#fig-SciModel_pop fig-align="center" width=70%}

<!-- check the directionality of the arrow from $p_{I}$ to $\sigma_{i(g)}$ and equivalents -->


![ DCJ causal diagram, sample with comparisons mathematical description ](images/figures/SciModel_samp.png){#fig-SciModel_samp fig-align="center" width=80%}

<!-- Assuming certain values are decided in the experimental design (proportions, sample size, etc) you can reduce the graph -->

<!-- It is more likely that we can decide the characteristics of the objects we want to include in the study (independent variables), ensuring groups that are more balanced. However, in the case of subjects sometimes the independent variables cannot be assigned (e.g., hearing status) -->


## Probabilitics assumptions of the scientific model {#sec-theory-probability}

<!-- what does it mean in probabilistic terms? describe probabilities and arrive to structural model -->

<!-- Final models does not require the estimation of latent variables, the results can be evaluated without them -->

<!-- Notice that latent variables are kind of like descendants -->


<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} := & \; f_{O}( \delta_{kijr_{ij}} ) \\ -->
<!--   \delta_{kijr_{ij}} := & \; f_{D}( \gamma_{k}, \theta_{ir_{i}} ) \\ -->
<!--   \gamma_{k} := & \; f_{G}( Z_{k}, e_{k} ) \\ -->
<!--   \theta_{ir_{i}} := & \; f_{R}( \theta_{i}, Y_{r}, e_{r_{i}} ) \\ -->
<!--   \theta_{i} := & \; f_{T}( X_{i}, e_{i} ) \\ -->
<!--   & \; e_{k} \dsep e_{i} \\ -->
<!--   & \; e_{k} \dsep e_{r_{i}} \\ -->
<!--   & \; e_{i} \dsep e_{r_{i}} -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StructuralModel} -->



## From the scientific to statistical model {#sec-theory-statistics}

<!-- "An appropriate analysis of data cannot be completed without knowledge of what experimental design was used and how the data was collected, and conclusions are not reliable if they are not justified by the proper modeling and analysis of the data" (Lawson, 2015, p. 7) -->

<!-- "In many cases where observational units are different than the experimental units, the observational units will not be independent" (p. 177) -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} \sim & \; \text{Bernoulli}\left[ \; logit^{-1}\left( \delta_{kijr_{ij}} \right) \; \right] \\ -->
<!--   \delta_{kijr_{ij}} = & \; \gamma_{k}( \theta_{ir_{i}} - \theta_{jr_{j}} ) \\ -->
<!--   \gamma_{k} = & \; logit^{-1}\left[ \beta_{Z} Z_{k} + e_{k} \right] \\ -->
<!--   \theta_{ir_{i}} = & \; \theta_{i} + \beta_{Y} Y_{r} + e_{r_{i}}  \\ -->
<!--   \theta_{i} = & \; \beta_{X} X_{i} + e_{i}  \\ -->
<!--   e_{k} \sim & \; \text{Normal}(0, \sigma_{k(g)}) \\ -->
<!--   e_{i} \sim & \; \text{Normal}(0, \sigma_{i(g)}) \\ -->
<!--   e_{r_{i}} \sim & \; \text{Normal}(0, \sigma_{r(g)}) -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StatModel_general} -->

<!-- for identification purposes we can set $\frac{1}{G}\sum_{g=1}^{G} \sigma_{k(g)} = 0.02$, $\frac{1}{G}\sum_{g=1}^{G} \sigma_{i(g)} = 1$, and $\frac{1}{G}\sum_{g=1}^{G} \sigma_{r(g)} = 1$. A special case of this would be to assume that the data comes from the same population, in that case, $\sigma_{k(g)} = \sigma_{k} = 0.02$, $\sigma_{i(g)} = \sigma_{i} = 1$ -->




## Let's talk about Thurstone {#sec-theory-thurstone}


<!-- Thurstone's comparative judgment @Thurstone_1927 is based on the formula: -->
<!-- $$ -->
<!-- X_{AB} = \frac{S_{A} - S_{B}}{\sigma_{AB}} -->
<!-- $$ -->

<!-- where $X_{AB}$ defines the comparative judgment outcome, $S_{A}$ and $S_{B}$ are the modal discriminal processes, $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B} + 2 \rho \sigma_{A} \sigma_{B}}$, with $\sigma_{A}$ and $\sigma_{B}$ being the dispersion of discriminal processes $A$ and $B$, respectively, and $\rho$ the correlation between discriminal processes.    -->

<!-- The theory identifies five cases: -->

<!-- - **Case 1:** only constant $\rho$ (not $\rho_{ij}$) -->
<!-- - **Case 2:** $X_{ij}$ becomes $X_{kij}$ with $k=1, \dots, K$ judges (replication, not duplication) -->
<!-- - **Case 3:** $\rho = 0$, then $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B}}$  -->
<!-- - **Case 4:** $\sigma_{B}=\sigma_{A}+d$, then $\lim_{d \leq 0.1\sigma_{A}} \sigma_{AB} = (\sigma_{A} + \sigma_{B}) /\sqrt{2}$ -->
<!-- - **Case 5:** $\sigma_{B}=\sigma_{A}$, then $\sigma_{AB} = \sqrt{2}\sigma$ -->

<!-- Now using the DAG and statistical notation -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} := & \; f_{O}( \delta_{kijr_{ij}} ) \\ -->
<!--   \delta_{kijr_{ij}} = & \; \gamma_{k}( \theta_{ir_{i}} - \theta_{jr_{j}} ) \\ -->
<!--   \gamma_{k} = & \; f_{G}( Z_{k}, e_{k} ) \\ -->
<!--   \theta_{ir_{i}} = & \; \theta_{i} + \beta_{Y} Y_{r} + e_{r_{i}}  \\ -->
<!--   \theta_{i} = & \; \beta_{X} X_{i} + e_{i}  \\ -->
<!--   e_{k} \sim & \; \text{Normal}(0, \sigma_{k(g)}) \\ -->
<!--   e_{i} \sim & \; \text{Normal}(0, \sigma_{i(g)}) \\ -->
<!--   e_{r_{i}} \sim & \; \text{Normal}(0, \sigma_{r(g)}) -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StatModel_thurstone} -->

<!-- The theory identifies five cases: -->

<!-- - **Case 1:** only constant $\rho \approx \sigma_{i}$ -->
<!-- - **Case 2:** now judges are separated by using $\gamma_{k}$ -->
<!-- - **Case 3:** $\rho \approx \sigma_{e_{i}} = 0$ (no nesting of texts on students), then $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B}}$  -->
<!-- - **Case 4:** $\sigma_{B}=\sigma_{A}+d$, then $\lim_{d \leq 0.1\sigma_{A}} \sigma_{AB} = (\sigma_{A} + \sigma_{B}) /\sqrt{2}$ -->
<!-- - **Case 5:** $\sigma_{B}=\sigma_{A}$, then $\sigma_{AB} = \sqrt{2}\sigma$ -->

<!-- But now can we see other scenarios than just those 5 cases? -->

<!-- - consider different $\rho \approx \sum_{p=1}^{P} \sigma_{p}$, depending on $P$ nesting structures  -->
<!-- - we can now investigate $\gamma_{k}$ -->
<!-- - we can assume $\sigma_{B} \neq \sigma_{A}$, no need for results on the limit -->


# Discussion {#sec-discuss}

## Findings {#sec-discuss-finding}

<!-- no fundamental ontological objections to using DAGs to describe causal models and causal relationships. -->

## Limitations and further research {#sec-discuss-limitations}
<!-- and most of the methods depend on unverifiable assumptions, causal inference can still identify causes and estimate their effects, assuming a set of plausibles mechanisms for a system. -->



# Conclusion {#sec-conclusion}



{{< pagebreak >}}

# Declarations {.appendix .unnumbered}

**Funding:** The project was founded through the Research Fund of the University of Antwerp (BOF).

**Financial interests:** The authors have no relevant financial interest to disclose.

**Non-financial interests:** Author XX serve on advisory broad of Company Y but receives no compensation this role.

**Ethics approval:** The University of Antwerp Research Ethics Committee has confirmed that no ethical approval is required.

**Consent to participate:** Not applicable

**Consent for publication:** All authors have read and agreed to the published version of the manuscript.

**Availability of data and materials:** No data was utilized in this study.

**Code availability:** All the code utilized in this research is available in the digital document located at: [https://jriveraespejo.github.io/paper2_manuscript/](https://jriveraespejo.github.io/paper2_manuscript/).  

**Authors' contributions:** *Conceptualization:* S.G., S.DM., T.vD., and J.M.R.E; *Methodology:* S.DM., T.vD., and J.M.R.E; *Software:* J.M.R.E.; *Validation:* J.M.R.E.; *Formal Analysis:* J.M.R.E.; *Investigation:* J.M.R.E; *Resources:* S.G., S.DM., and T.vD.; *Data curation:* J.M.R.E.; *Writing - original draft:* J.M.R.E.; *Writing - review & editing:* S.G., S.DM., and T.vD.; *Visualization:* J.M.R.E.; *Supervision:* S.G. and S.DM.; *Project administration:* S.G. and S.DM.; *Funding acquisition:* S.G. and S.DM.

<!-- **Acknowledgements:** NO additional acknowledgements -->



{{< pagebreak >}}

# Appendix {#sec-appendix}

## Why do we need to estimate judges' abilities? {#sec-appA}

<!-- The same idea as interactions: when interactions are significant, the interpretations of the parameters cannot be made in isolation -->

## Latent variables as a mean of imputation {#sec-appB}

<!-- Latent variables and random effects are in essence imputation? (McElreath, p. 504) -->
<!-- Judge index works as a descendant of the latent variables, or the latent variable is not a reflective, but generative where the index is multiplied by a loading? -->
<!-- see Morgan et al (2014) -->
<!-- see Mayer (2019) -->

## Other comparative scenarios  {#sec-appC}

{{< pagebreak >}}

## References {.unnumbered}

:::{#refs}

:::