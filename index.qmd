---
title: "Causes and effects in Dichotomous Comparative Judgments: an information-theoretical system with plausible mechanism"
author:
  - name: 
      given: Jose Manuel
      family: Rivera Espejo
    orcid: 0000-0002-3088-2783
    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/
    email: JoseManuel.RiveraEspejo@uantwerpen.be
    corresponding: true
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: lead
      - methodology: lead
      - software: only
      - validation: only
      - formal analysis: only
      - investigation: only
      - resources: no
      - data curation: only
      - writing: only
      - editing: no
      - visualization: only
      - supervision: no
      - project administration: no
      - funding adquisition: no
  - name: 
      given: Tine
      family: van Daal
      non-dropping-particle: van
    orcid: https://orcid.org/0000-0001-9398-9775
    url: https://www.uantwerpen.be/en/staff/tine-vandaal/
    email: tine.vandaal@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: support
      - methodology: support
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: no
      - project administration: no
      - funding adquisition: no
  - name: 
      given: Sven
      family: De Maeyer
      non-dropping-particle: De
    orcid: 0000-0003-2888-1631
    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/
    email: sven.demaeyer@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
    roles: 
      - conceptualization: support
      - methodology: support
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: yes
      - project administration: yes
      - funding adquisition: yes
  - name: 
      given: Steven
      family: Gillis
    orcid: 
    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/
    email: steven.gillis@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Linguistics
        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)
    roles: 
      - conceptualization: support
      - methodology: no
      - software: no
      - validation: no
      - formal analysis: no
      - investigation: no
      - resources: support
      - data curation: no
      - writing: no
      - editing: support
      - visualization: no
      - supervision: yes
      - project administration: yes
      - funding adquisition: yes
funding: 
  statement: "The project was founded through the Research Fund of the University of Antwerp (BOF)."
keywords:
  - comparative judgement
  - directed acycilc graph
  - causal analysis
  - probabilistic statistics
abstract: |
  Dichotomous Comparative Judgment (DCJ) requires judges to compare pairs of stimuli to determine which one exhibits a higher degree of a specific trait. DCJ has proven effective and reliable across various fields [@Pollitt_2012b; @Jones_2015; @vanDaal_et_al_2016; @Bartholomew_et_al_2018; @Lesterhuis_2018; @Bartholomew_et_al_2020; @Marshall_et_al_2020; @Boonen_et_al_2020]. However, despite the method's widespread use, existing literature lacks a clear explanation of the complexities and assumptions underpinning the DCJ system, as well as the plausible mechanisms through which DCJ data could be generated. This study addresses these issues by representing DCJ within the framework of causal inference. Specifically, utilizing the structural approach, the study develops a scientific model to clarify the causal assumptions and mechanisms inherent in the DCJ system. It then translates this model into a probabilistic statistical framework to estimate statistical relationships and infer causal effects within the system. This research provides a robust probabilistic foundation for the statistical analysis of DCJ data, building upon Thurstone’s law of comparative judgment [-@Thurstone_1927]. Its findings offer valuable insights for researchers and analysts designing and implementing DCJ experiments.
key-points:
  - (to do)
date: last-modified
bibliography: references.bib
notebook-links: global
citation: true
  # type: article-journal
  # container-title: "Psychometrika"
  # doi: ""
  # # url: https://example.com/summarizing-output
execute: 
  cache: true
  # eval: true
  echo: false
  # output: true
  # include: true
  warning: false
  error: false
  message: false
---

# Introduction {#sec-introduction}

<!-- 1. What is comparative judgment? -->
In contemporary contexts, Thurstone's law of comparative judgment [-@Thurstone_1927] primarily refers to the method of *dichotomous* comparative judgment [DCJ, @Pollitt_2012a; @Pollitt_2012b]. In DCJ, a judge assesses the relative manifestation of a *trait* within a pair of stimuli. This assessment results in a dichotomous value indicating which stimulus possesses a higher degree of the trait. After different judges perform multiple rounds of pairwise comparisons, an outcome vector is produced. This vector is modeled using the Bradley-Terry-Luce model [BTL, @Bradley_et_al_1952; @Luce_1959], which creates a score that corresponds with the trait of interest. This score is then used to rank the stimuli from lowest to highest or to evaluate the influence of certain variables on the stimuli's positions in the ranking.

<!-- 2. in what has been applied on?, and where is the gap? -->
DCJ has proven effective in assessing competencies and traits predominantly within the educational realm, as demonstrated by @Pollitt_2012b, @Jones_2015, @vanDaal_et_al_2016, @Bartholomew_et_al_2018, @Lesterhuis_2018, @Bartholomew_et_al_2020, and @Marshall_et_al_2020. However, its application transcends education, as exemplified by @Boonen_et_al_2020. The methodology has also evolved to include multiple, as opposed to pairwise comparisons [@Luce_1959; @Placket_1975], and to accommodate comparisons with ordinal outcomes [@Tutz_1986; @Agresti_1992]. Overall, research suggests that DCJ offers an alternative and efficient approach to measurement and evaluation, characterized by its reliability and validity [@Lesterhuis_2018; @vanDaal_2020; @Marshall_et_al_2020]. Nevertheless, despite the method's widespread use, existing literature lacks a clear representation of the plausible mechanisms through which DCJ data could be generated. Particularly, there is no depiction of the complexity and the assumptions underpinning the DCJ system, nor how different assessment factors can potentially influence the observed DCJ outcome.

<!-- 3. What are the factors behind DCJ? -->
According to @Verhavert_et_al_2019 and @vanDaal_2020, several assessment factors interact and influence the method's outcome. These factors include the number and characteristics of the stimuli, their *proximity* in terms of the assessed trait, the number of comparison per stimulus, and the pairing algorithm used. Furthermore, since the method relies on judges' assessments, the number and characteristics of judges, their *discrimination* abilities, and the number of comparisons per judge also play pivotal roles. Moreover, when the stimuli represent sub-units of higher-levels units, factors such as the number and characteristics of these units, along with their *proximity* in terms of the assessed trait, can significantly influence the outcome. For instance, @vanDaal_et_al_2016 assessed academic writing skills of university students (units) using multiple argumentative essays (sub-units).

<!-- 4. Solution to the gap -->
Although several studies have examined the individual impact of these factors on the method's reliability [@Bramley_2015; @Pollitt_2012b; @Bramley_et_al_2019; @Verhavert_et_al_2019; @Crompvoets_et_al_2022; @vanDaal_et_al_2017; @Gijsen_et_al_2021], none, to the best of the authors' knowledge, have provided a transparent depiction of the DCJ system and the mechanisms generating the DCJ outcome. This study aims to fill this gap by representing DCJ within the framework of causal inference. Specifically, utilizing the structural approach [@Wright_1921; @Pearl_2009; @Pearl_et_al_2016], the study develops a scientific model to clarify the causal assumptions and mechanisms inherent in the DCJ system. Next, using a minimal set of assumptions, the study translates the scientific model into a probabilistic statistical model. This model aims to produce statistical estimates to draw inferences about plausible causal relationships within the DCJ system. 

<!-- 5. final objective and relevance -->
Ultimately, this research provides a robust probabilistic foundation for the statistical analysis of DCJ data, building upon Thurstone’s law of comparative judgment [-@Thurstone_1927]. Consequently, its findings offer valuable insights for researchers and analysts designing and implementing DCJ experiments.


# Theoretical background {#sec-background}

## The structural approach to causal inference {#sec-background-structural}

<!-- 1. What is causal inference? -->
In statistics, *causal inference* refers to the process of identifying the causes of a phenomenon and estimating their effects using data [@Shaughnessy_et_al_2010; @Neal_2020]. Unlike classical statistical modeling, which focuses solely on summarizing data and inferring associations, causal inference provides a coherent mathematical notation for analyzing causes and counterfactuals [@Pearl_2009]. 

<!-- 2. what are counterfactuals? -->
Counterfactuals represent scenarios *contrary to fact*, where alternative *potential* outcomes resulting from a cause are neither observed nor observable [@Neal_2020; @Counterfactual_2024]. According to @Pearl_et_al_2018, counterfactuals form the foundation of causal inference and occupy the highest level of cognitive abstraction in the ladder of causation, followed by intervention and association. Despite this abstract nature, counterfactuals enable the development of a *theory of the world* that explains why specific causes have specific effects and what occurs in their absence [@Pearl_et_al_2018]. They achieve this by translating causal statements into counterfactual statements, that is, statements about "what would have happened in the world under different circumstances."

<!-- 3. How do we apply causal inference and counterfactuals? -->
Several approaches to causal inference and counterfactuals exist, but two are particularly prominent: the potential outcomes approach, also known as the Neyman-Rubin causal model [@Neyman_et_al_1923; @Rubin_1974], and the structural approach [@Wright_1921; @Pearl_2009; @Pearl_et_al_2016]. Both approaches employ rigorous mathematical notation to characterize causal inference, but they do so in different ways [@Neal_2020]. The potential outcomes approach relies on counterfactual notation, whereas the structural approach employs the do-operator and structural causal models [SCM, @Pearl_2009; @Pearl_et_al_2016]. Despite these differences, both notations can be expressed in terms of the other, and both approaches provide methods for using experimental and observational data to estimate causal effects [@Pearl_2010]. 

<!-- 4. But which approach are we going to use? -->
Nevertheless, the structural approach offers an additional key advantage over the potential outcomes approach: it enables the graphical representation of any system through directed acyclic graphs [DAG, @Gross_et_al_2018; @Neal_2020]. DAGs are heuristics that can effectively convey the assumed causal structure of a system. They do not represent detailed statistical models but allow researchers to deduce which statistical models can provide valid causal inferences, assuming the causal structure depicted in the DAG is accurate [@McElreath_2020].

<!-- A Directed Acyclic Graph (DAG) allows for the transparent depiction of a system’s complexity, revealing its underlying assumptions and the plausible mechanisms generating the system’s outcome, assuming the DAG is true.  -->

## DAGs, SCMs, and the flow of association and causation {#sec-background-dag}

<!-- 1. What are DAGs? and how are they represented? -->
Graph theory is a branch of mathematics focused on the study of graphs. Graphs are mathematical structures that model pairwise relations between objects. They can represent physical relations, such as electrical circuits and roadways, and less tangible structures, such as ecosystems and sociological relations[@Gross_et_al_2018]. Graphs have proven useful in various fields, spanning statistics, computer science, operations research, and the natural and social sciences. One application in statistics that incorporates concepts from graph theory is causal inference. Specifically, the structural approach to causal inference uses directed acyclic graphs (DAG) to provide a formal and graphical representation of the causal structure of a system [@Neal_2020].

A graph is a collection of nodes connected by edges. In a directed graph, edges extend from a *parent* node to a *child* node, with arrows indicating the direction of the causal influence. Two nodes that are connected by edge are said to be *adjacent* [@Gross_et_al_2018]. In a directed acyclic graph (DAG), the direction of causal influences does not loop back on itself, ensuring that the graph contains no cycles [@Neal_2020; @McElreath_2020].





<!-- To draw a DAG use the exclusion restriction assumption: a variable should not appear in the graph if it is not a part of the causal mechanisms that generate the outcome under analysis (see Neal, 2020). -->

<!-- 2. What does a DAG imply? -->
<!-- and utilizes the do-operator and Structural Causal Models (SCMs) for mathematical notation in causal inference. -->
<!-- Structural Causal Model (SCM) -->
<!-- Causal models are mathematical models representing causal relationships within an individual system or population. They facilitate inferences about causal relationships from statistical data. They can teach us a good deal about the epistemology of causation, and about the relationship between causation and probability. They have also been applied to topics of interest to philosophers, such as the logic of counterfactuals, decision theory, and the analysis of actual causation. -->


<!-- 3. But what are those mysterious functions?, and how do they become statistical quantities? -->
![ The flow of association and causation in graphs. Extracted from @Neal_2020 [pp. 31] ](images/figures/ACflow.png){#fig-ACflow fig-align="center" width=100%}


<!-- 4. What is the local markov assumption? and where does it lead? -->

<!-- 5. What is the minimality assumption? and where does it lead? -->


<!-- 6. What is the causal edges assumption? and where does it lead? -->

<!-- 7. putting it all together -->


<!-- 8. What are the DAG's building blocks?, and what do they imply? (SCMs) -->
<!-- Ultimately, DAGs play the important role of identifying which variables should be controlled for to be able to estimate causal effects. -->



## But where does it all fit? {#sec-background-where}

<!-- 4. But how do we move from targets of inference to estimates -->
<!-- But how can we move from heuristics and vague mathematic notation, to probabilistic causal analysis. -->


<!-- Before tackling the main objective of this study, however, it is important to understand how researchers can move from causal estimands to statistical estimates. Causal estimands, also known as targets of inference, are the quantities that the researcher wants to estimate. Usually, these quantities are articulated through different research questions and they are depicted using the language of the Potential Outcomes framework, Neyman-Rubin causal framework [@Neyman_et_al_1990; @Rubin_1974] mathematical expectation, e.g., $E[Y_{i}(1) - Y_{i}(0)]$ indicating that a researcher is interested in estimating the *average treatment effect* (ATE) -->

<!-- This study uses the Identification-Estimation flowchart [@McElreath_2020; @Neal_2020]. The flowchart illustrates the process of moving from a target (causal) *estimand* to a corresponding *estimate*, through identification and estimation (@fig-IEflowchart).  -->

<!-- Initially, it defines the different targets of inference (i.e., the *estimands*), which form the basis for evaluating the reliability of the DCJ method. The targets  Subsequently, the research constructs a *scientific model* for the DCJ procedure, elucidating the causal assumptions and mechanisms underlying the system, aiding in drawing inferences about causal relationships from DCJ data. Next, the study translates the scientific model into a probabilistic statistical model (i.e., an *estimator*) to derive a *statistical estimand* for the various inference targets. Bayesian statistical methods offer an intuitive approach for the task. Finally, employing multiple simulated datasets for different combinations of the relevant assessment factors, the study generates multiple *estimates* or approximations for the statistical estimands. Notably, the statistical estimands in simulated data are known, enabling the study to assess the reliability of DCJ by evaluating the *proximity* of these estimands to the generated estimates, resembling a power analysis. -->


<!-- In this context, identification refers to the process of moving from a (causal) *estimand* to an equivalent *statistical estimand*, and estimation refers to the process of moving from a *statistical estimand* to an *estimate*. -->

![ Identification-Estimation flowchart. Extracted from @Neal_2020 [pp. 32] ](images/figures/IEflow.png){#fig-IEflow fig-align="center" width=40%}





# Theoretical framework {#sec-theory}

## A scientific model for the DCJ {#sec-theory-scientific}


<!-- A *scientific (causal) model* describe the causal assumptions and mechanisms underlying a system, and facilitate inferences about causal relationships from data [@Hitchcock_2023]. -->

<!-- From Lawson (2015), another way to see DCJ experiments I'd that you are grouping heterogeneous experimental units (objects) into homogeneous ones (subjects), which are your "blocks" -->


![ DCJ causal diagram, simplified description ](images/figures/SciModel_simp1.png){#fig-SciModel_simp1 fig-align="center" width=80%}

![ DCJ causal diagram, simplified mathematical description ](images/figures/SciModel_simp2.png){#fig-SciModel_simp2 fig-align="center" width=70%}

![ DCJ causal diagram, population mathematical description ](images/figures/SciModel_pop.png){#fig-SciModel_pop fig-align="center" width=70%}

<!-- check the directionality of the arrow from $p_{I}$ to $\sigma_{i(g)}$ and equivalents -->


![ DCJ causal diagram, sample with comparisons mathematical description ](images/figures/SciModel_samp.png){#fig-SciModel_samp fig-align="center" width=80%}


<!-- It is more likely that we can decide the characteristics of the objects we want to include in the study (independent variables), ensuring groups that are more balanced. However, in the case of subjects sometimes the independent variables cannot be assigned (e.g., hearing status) -->


## Probabilitics assumptions of the scientific model {#sec-theory-probability}

<!-- what does it mean in probabilistic terms? describe probabilities and arrive to structural model -->

<!-- commands for d-separation -->
<!-- \newcommand{\dsep}{\perp\!\!\!\perp} -->
<!-- \newcommand{\ndsep}{\not\!\perp\!\!\!\perp} -->


<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} := & \; f_{O}( \delta_{kijr_{ij}} ) \\ -->
<!--   \delta_{kijr_{ij}} := & \; f_{D}( \gamma_{k}, \theta_{ir_{i}} ) \\ -->
<!--   \gamma_{k} := & \; f_{G}( Z_{k}, e_{k} ) \\ -->
<!--   \theta_{ir_{i}} := & \; f_{R}( \theta_{i}, Y_{r}, e_{r_{i}} ) \\ -->
<!--   \theta_{i} := & \; f_{T}( X_{i}, e_{i} ) \\ -->
<!--   & \; e_{k} \dsep e_{i} \\ -->
<!--   & \; e_{k} \dsep e_{r_{i}} \\ -->
<!--   & \; e_{i} \dsep e_{r_{i}} -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StructuralModel} -->



## From the scientific to statistical model {#sec-theory-statistics}

<!-- "An appropriate analysis of data cannot be completed without knowledge of what experimental design was used and how the data was collected, and conclusions are not reliable if they are not justified by the proper modeling and analysis of the data" (Lawson, 2015, p. 7) -->

<!-- "In many cases where observational units are different than the experimental units, the observational units will not be independent" (p. 177) -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} \sim & \; \text{Bernoulli}\left[ \; logit^{-1}\left( \delta_{kijr_{ij}} \right) \; \right] \\ -->
<!--   \delta_{kijr_{ij}} = & \; \gamma_{k}( \theta_{ir_{i}} - \theta_{jr_{j}} ) \\ -->
<!--   \gamma_{k} = & \; logit^{-1}\left[ \beta_{Z} Z_{k} + e_{k} \right] \\ -->
<!--   \theta_{ir_{i}} = & \; \theta_{i} + \beta_{Y} Y_{r} + e_{r_{i}}  \\ -->
<!--   \theta_{i} = & \; \beta_{X} X_{i} + e_{i}  \\ -->
<!--   e_{k} \sim & \; \text{Normal}(0, \sigma_{k(g)}) \\ -->
<!--   e_{i} \sim & \; \text{Normal}(0, \sigma_{i(g)}) \\ -->
<!--   e_{r_{i}} \sim & \; \text{Normal}(0, \sigma_{r(g)}) -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StatModel_general} -->

<!-- for identification purposes we can set $\frac{1}{G}\sum_{g=1}^{G} \sigma_{k(g)} = 0.02$, $\frac{1}{G}\sum_{g=1}^{G} \sigma_{i(g)} = 1$, and $\frac{1}{G}\sum_{g=1}^{G} \sigma_{r(g)} = 1$. A special case of this would be to assume that the data comes from the same population, in that case, $\sigma_{k(g)} = \sigma_{k} = 0.02$, $\sigma_{i(g)} = \sigma_{i} = 1$ -->




## Let's talk about Thurstone {#sec-theory-thurstone}


<!-- Thurstone's comparative judgment @Thurstone_1927 is based on the formula: -->
<!-- $$ -->
<!-- X_{AB} = \frac{S_{A} - S_{B}}{\sigma_{AB}} -->
<!-- $$ -->

<!-- where $X_{AB}$ defines the comparative judgment outcome, $S_{A}$ and $S_{B}$ are the modal discriminal processes, $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B} + 2 \rho \sigma_{A} \sigma_{B}}$, with $\sigma_{A}$ and $\sigma_{B}$ being the dispersion of discriminal processes $A$ and $B$, respectively, and $\rho$ the correlation between discriminal processes.    -->

<!-- The theory identifies five cases: -->

<!-- - **Case 1:** only constant $\rho$ (not $\rho_{ij}$) -->
<!-- - **Case 2:** $X_{ij}$ becomes $X_{kij}$ with $k=1, \dots, K$ judges (replication, not duplication) -->
<!-- - **Case 3:** $\rho = 0$, then $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B}}$  -->
<!-- - **Case 4:** $\sigma_{B}=\sigma_{A}+d$, then $\lim_{d \leq 0.1\sigma_{A}} \sigma_{AB} = (\sigma_{A} + \sigma_{B}) /\sqrt{2}$ -->
<!-- - **Case 5:** $\sigma_{B}=\sigma_{A}$, then $\sigma_{AB} = \sqrt{2}\sigma$ -->

<!-- Now using the DAG and statistical notation -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!--   O_{kijr_{ij}} := & \; f_{O}( \delta_{kijr_{ij}} ) \\ -->
<!--   \delta_{kijr_{ij}} = & \; \gamma_{k}( \theta_{ir_{i}} - \theta_{jr_{j}} ) \\ -->
<!--   \gamma_{k} = & \; f_{G}( Z_{k}, e_{k} ) \\ -->
<!--   \theta_{ir_{i}} = & \; \theta_{i} + \beta_{Y} Y_{r} + e_{r_{i}}  \\ -->
<!--   \theta_{i} = & \; \beta_{X} X_{i} + e_{i}  \\ -->
<!--   e_{k} \sim & \; \text{Normal}(0, \sigma_{k(g)}) \\ -->
<!--   e_{i} \sim & \; \text{Normal}(0, \sigma_{i(g)}) \\ -->
<!--   e_{r_{i}} \sim & \; \text{Normal}(0, \sigma_{r(g)}) -->
<!-- \end{aligned} -->
<!-- $$ {#eq-StatModel_thurstone} -->

<!-- The theory identifies five cases: -->

<!-- - **Case 1:** only constant $\rho \approx \sigma_{i}$ -->
<!-- - **Case 2:** now judges are separated by using $\gamma_{k}$ -->
<!-- - **Case 3:** $\rho \approx \sigma_{e_{i}} = 0$ (no nesting of texts on students), then $\sigma_{AB} = \sqrt{ \sigma^{2}_{A} + \sigma^{2}_{B}}$  -->
<!-- - **Case 4:** $\sigma_{B}=\sigma_{A}+d$, then $\lim_{d \leq 0.1\sigma_{A}} \sigma_{AB} = (\sigma_{A} + \sigma_{B}) /\sqrt{2}$ -->
<!-- - **Case 5:** $\sigma_{B}=\sigma_{A}$, then $\sigma_{AB} = \sqrt{2}\sigma$ -->

<!-- But now can we see other scenarios than just those 5 cases? -->

<!-- - consider different $\rho \approx \sum_{p=1}^{P} \sigma_{p}$, depending on $P$ nesting structures  -->
<!-- - we can now investigate $\gamma_{k}$ -->
<!-- - we can assume $\sigma_{B} \neq \sigma_{A}$, no need for results on the limit -->


# Discussion {#sec-discuss}

## Findings {#sec-discuss-finding}

## Limitations and further research {#sec-discuss-limitations}
<!-- and most of the methods depend on unverifiable assumptions, causal inference can still identify causes and estimate their effects, assuming a set of plausibles mechanisms for a system. -->



# Conclusion {#sec-conclusion}



{{< pagebreak >}}

# Declarations {.appendix .unnumbered}

**Funding:** The project was founded through the Research Fund of the University of Antwerp (BOF).

**Financial interests:** The authors have no relevant financial interest to disclose.

**Non-financial interests:** Author XX serve on advisory broad of Company Y but receives no compensation this role.

**Ethics approval:** The University of Antwerp Research Ethics Committee has confirmed that no ethical approval is required.

**Consent to participate:** Not applicable

**Consent for publication:** All authors have read and agreed to the published version of the manuscript.

**Availability of data and materials:** No data was utilized in this study.

**Code availability:** All the code utilized in this research is available in the digital document located at: [https://jriveraespejo.github.io/paper2_manuscript/](https://jriveraespejo.github.io/paper2_manuscript/).  

**Authors' contributions:** *Conceptualization:* S.G., S.DM., T.vD., and J.M.R.E; *Methodology:* S.DM., T.vD., and J.M.R.E; *Software:* J.M.R.E.; *Validation:* J.M.R.E.; *Formal Analysis:* J.M.R.E.; *Investigation:* J.M.R.E; *Resources:* S.G., S.DM., and T.vD.; *Data curation:* J.M.R.E.; *Writing - original draft:* J.M.R.E.; *Writing - review & editing:* S.G., S.DM., and T.vD.; *Visualization:* J.M.R.E.; *Supervision:* S.G. and S.DM.; *Project administration:* S.G. and S.DM.; *Funding acquisition:* S.G. and S.DM.

<!-- **Acknowledgements:** NO additional acknowledgements -->



{{< pagebreak >}}

# Appendix {#sec-appendix}

## Additional definitions {#sec-appA}


## Why do we need to estimate judges' abilities? {#sec-appB}

<!-- The same idea as interactions: when interactions are significant, the interpretations of the parameters cannot be made in isolation -->

{{< pagebreak >}}

## References {.unnumbered}

:::{#refs}

:::