{
  "hash": "199d04e4506796b948f15948cb49f01e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Let's talk about Thurstone & Co.: An information-theoretical model for comparative judgments, and its statistical translation\"\nauthor:\n  - name: \n      given: Jose Manuel\n      family: Rivera Espejo\n    orcid: 0000-0002-3088-2783\n    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/\n    email: JoseManuel.RiveraEspejo@uantwerpen.be\n    corresponding: true\n    affiliation:\n      - name: University of Antwerp\n        department: Training and education sciences\n        group: Edubron\n  - name: \n      given: Tine\n      family: van Daal\n      non-dropping-particle: van\n    orcid: https://orcid.org/0000-0001-9398-9775\n    url: https://www.uantwerpen.be/en/staff/tine-vandaal/\n    email: tine.vandaal@uantwerpen.be\n    corresponding: false\n    affiliation:\n      - name: University of Antwerp\n        department: Training and education sciences\n        group: Edubron\n  - name: \n      given: Sven\n      family: De Maeyer\n      non-dropping-particle: De\n    orcid: 0000-0003-2888-1631\n    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/\n    email: sven.demaeyer@uantwerpen.be\n    corresponding: false\n    affiliation:\n      - name: University of Antwerp\n        department: Training and education sciences\n        group: Edubron\n  - name: \n      given: Steven\n      family: Gillis\n    orcid: \n    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/\n    email: steven.gillis@uantwerpen.be\n    corresponding: false\n    affiliation:\n      - name: University of Antwerp\n        department: Linguistics\n        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)\nfunding: \n  statement: \"The project was founded through the Research Fund of the University of Antwerp (BOF).\"\nkeywords:\n  - Probability\n  - Directed Acyclic Graphs\n  - Bayesian methods\n  - Thurstonian model\n  - Comparative judgement\n  - Structural Causal Models\n  - Statistical modeling\nabstract: |\n  (to do)\nkey-points:\n  - (to do)\ndate: last-modified\nbibliography: references.bib\nnotebook-links: global\nlightbox: true\ncitation: true\n  # type: article-journal\n  # container-title: \"Psychometrika\"\n  # doi: \"\"\n  # # url: https://example.com/summarizing-output\nexecute: \n  cache: true\n  # eval: true\n  echo: false\n  # output: true\n  # include: true\n  warning: false\n  error: false\n  message: false\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# # load packages\n# libraries = c('RColorBrewer','stringr','dplyr','tidyverse',\n#               'rechape2','knitr','kableExtra',\n#               'rstan','StanHeaders','runjags','rethinking')\n# sapply(libraries, require, character.only=T)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# # load functions\n# main_dir = '/home/josema/Desktop/1. Work/1 research/PhD Antwerp/#thesis/paper2/paper2_manuscript'\n# source( file.path( main_dir, 'code', 'user-defined-functions.R') )\n```\n:::\n\n\n# Introduction {#sec-introduction}\n\n<!-- recording 1 -->\n<!-- Part 1; 00:00:00 - 00:09:10 -->\n\n<!-- recording 2 -->\n<!-- Part 2; 00:00:00 - 00:17:30 -->\n\n<!-- 1. What does CJ do? -->\nIn *comparative judgment* (CJ) studies, judges assess the presence of a trait or competence by conducting pairwise comparisons of stimuli [@Thurstone_1927; @Pollitt_2004; @Pollitt_2012a]. The comparison produces a dichotomous outcome, indicating which stimulus is perceived to possess a higher trait level. After conducting multiple rounds of pairwise comparisons, researchers use the Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] to process the outcomes and estimate scores that reflect the underlying trait of interest. This method has been successfully employed in assessing the quality of written texts, where quality describes the underlying trait of interest and the texts serve as the stimuli [@Laming_2004; @Pollitt_2012b; @Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018; @Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023].\n\n<!-- Specifically, CJ has been used to evaluate the quality of written texts [@Laming_2004; @Pollitt_2012b; @Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018; @Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023] and to assess the quality of speech [@Boonen_et_al_2020]. Additionally, it has been applied to evaluate various competencies, including mathematical problem-solving skills [@Jones_2015], engineering design skills [@Bartholomew_et_al_2018], conceptual understanding in algebra [@Jones_et_al_2019], statistical and English knowdlege [@Marshall_et_al_2020], and STEM knowledge and skills [@Bartholomew_et_al_2020]. -->\n\n<!-- 2. Where are we now with DCJ? -->\nNumerous studies have documented the effectiveness of CJ in assessing various traits and competencies over the past decade. These studies have emphasized three aspects of the method's effectiveness: its reliability, validity, and practical applicability. Research on reliability indicates that CJ requires a relatively small number of pairwise comparisons [@Verhavert_et_al_2019; @Crompvoets_et_al_2022] to produce trait scores that are as precise and consistent as those generated by other assessment methods [@Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023]. Furthermore, evidence suggests that the reliability and time efficiency of CJ are comparable, if not superior, to those of other assessment methods when employing adaptive comparison algorithms [@Pollitt_2012b; @Verhavert_et_al_2022; @Mikhailiuk_et_al_2021]. Additionally, research on validity suggests that scores generated by CJ can accurately represent the traits under measurement [@Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018; @Bartholomew_et_al_2018; @Bouwer_et_al_2023]. Finally, research on practical applicability highlights the method's versatility across both educational and non-educational contexts [@Jones_2015; @Bartholomew_et_al_2018; @Jones_et_al_2019; @Marshall_et_al_2020; @Bartholomew_et_al_2020; @Boonen_et_al_2020].\n\n<!-- rubrics [@Coertjens_et_al_2017; @Goossens_et_al_2018]  -->\n<!-- holistic benchmark ratings [@Bouwer_et_al_2023] -->\n\n<!-- Adaptive comparison algorithms dynamically present stimuli to judges, based on the results of previous comparisons. They aim to enhance the informativeness of comparisons while optimizing judges' time [@Bramley_2015].  -->\n\n<!-- 3. But what are the problems of DCJ as a method? -->\nNevertheless, despite the growing number of CJ studies, the literature's unsystematic and fragmented research approaches have left several critical issues unaddressed. This research primarily focuses on three: the apparent disconnect between CJ's measurement and structural model, the over-reliance on the assumptions of Thurstone's Case 5 [-@Thurstone_1927] in CJ's measurement model, and the unclear role of comparison algorithms on the method's reliability and validity. The following sections will discuss each of these issues in detail, followed by the introduction of a theoretical model and its statistical translation, which aims to address all three concerns simultaneously.\n\n\n# Three critical issues in CJ literature {#sec-theory-issues}\n\n## The disconnect between structural and measurement models\n\n<!-- 1. The BTL model is CJ's measurement model -->\nIn a typical CJ study, the BTL model serves as the measurement model for CJ [@Andrich_1978; @Bramley_2008]. A measurement model specifies how manifest variables contribute to the estimation of latent variables [@Everitt_et_al_2010]. For example, when evaluating text quality, the BTL model uses the dichotomous outcomes resulting from the pairwise comparisons (the manifest variables) to estimate scores that reflect the underlying quality level of the texts (the latent variable) [@Laming_2004; @Pollitt_2012b; @Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018; @Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023]. \n\n<!-- 2. But there is no structural model, only post estimation analyses -->\nResearchers then typically use the estimated BTL scores, or their transformations, to conduct additional analyses or hypothesis testing. The scores have been used to identify 'misfit' judges and stimuli [@Pollitt_2012b; @vanDaal_et_al_2017; @Goossens_et_al_2018], detect biases in judges' ratings [@Pollitt_et_al_2003; @Pollitt_2012b], calculate correlations with other assessment methods [@Goossens_et_al_2018; @Bouwer_et_al_2023], or test hypotheses related to the underlying trait of interest [@Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021].\n\n<!-- 3. But what is the problem with this? -->\nHowever, the statistical literature cautions against using estimated scores to conduct additional analyses or tests. A key consideration is that BTL scores are parameter estimates that inherently carry uncertainty. Ignoring this uncertainty when conducting separate analyses and tests can inflate their precision and statistical power, increasing the risk of committing a type I error [@McElreath_2020]. A type I error results when a null hypothesis is incorrectly rejected [@Everitt_et_al_2010]. \n\n<!-- 4. So, what is the solution?  -->\nTo mitigate these risks, principles from Structural Equation Modeling (SEM) [@Hoyle_et_al_2023; @Kline_et_al_2023] and Item Response Theory (IRT) [@deAyala_2009; @Fox_2010; @vanderLinden_et_al_2017] recommend conducting these analyses and tests within a structural model.  A structural model specify how different manifest or latent variables influence the latent variable of interest [@Everitt_et_al_2010]. This approach allows analyses that can account for both the scores and their uncertainties simultaneously, rather than treating them as separate elements. Therefore, an integrated approach that combines CJ’s structural and measurement models can offer significant advantages.\n\n\n## The assumptions of Case 5 and the measurement model\n\n<!-- []{style=\"color:red;\"}. -->\n\n<!-- 1. What are the five cases of Thurstone? -->\n\n\n<!-- 1. the BTL model is the statistical articulation of Case 5 -->\n\nFrom early on in the literature, it has been clear that the BTL model represents a statistical articulation of Thurstone's Case 5 [-@Thurstone_1927]. Talk about @Pollitt_et_al_2003 and @Bramley_2008.\n\n  What case 5 implies, Assumptions. Not a normal distribution but a logistic distribution\n\n  Table with assumptions\n\n\n<!-- 2. But this model hold the greater number of assumptions -->\n\n<!--   Although Case 5 was originally articulated to produce a \"rather coarse scaling\" of traits [@Thurstone_1927, p. 269], its assumptions have become predominant in the literature, but Thurstone's Case 5 is the case that holds the greater amount of simplifying assumptions. -->\n\n<!--   @Thurstone_1927 justify the use of case V, on multiple assumptions, but the most important for our purpose are three: -->\n\n<!--   (a) related to Case 2 and case 3, it assumes the correlation between stimuli is zero, this translates into the cancellation of judges effects by mean of opposing and equally weighted 'mood' and 'simultaneous contrasts' effects. This is demonstrated using the additive nature of the logit scale, which helps to cancel 'bias' judges effects.  -->\n\n<!--   Particularly on how CJ is used now, use the text example -->\n\n<!--   What we are saying is that the judges' effects depend on the stimuli, by means of an interaction (but present) or because the judges works as a confounder. This, in the best scenario, cause less precise estimates, and in the worst scenario, biased estimates. possibility of bias is hinted in @Bramley_2008, and later mentioned again in @Kelly_et_al_2022, and some evidence is found in @Pollitt_et_al_2003, @vanDaal_et_al_2017 and @Gijsen_et_al_2021 -->\n\n<!--   @Pollitt_et_al_2003 In Thurstone’s method each judge’s standard cancels out when a comparison is made, and any misfit between data and model must indicate a difference of some other kind. This is studied by analyzing the residuals that remain after the model is fitted to the data. Whenever one script is judged to have a higher value than a competing one it is expected to ‘win’ the comparison: if it does the residual will be small, but if it loses then the residual for that judge’s comparison of those two scripts will be large. Any patterns of large residuals will indicate some sort of bias – in this context bias simply means a source of systematic, rather than random, variability. indicates that one judge – Judge 5 – is significantly biased in some way. (Consider the problem of using adhoc methods) -->\n\n\n<!--   Moreover, a solution was already envisioned, @Andrich_1978 and @Wainer_et_al_1978 already showed that if judges effects are parametrized, it gets eliminated experimentally in the paired comparison method.  -->\n\n<!--   use the example of writing!!! -->\n\n\n<!--   (b) related to Case 3, it assumes the correlation between stimuli is zero, this also translates into the idea that stimuli are the main focus of estimation and analysis, but what happens when the focus of analysis is the individuals that generated those stimuli. Meaning there is an amount of correlation that it is not accounted for.  -->\n\n<!--   Here we loose precision, because we are not controlling for clustering -->\n\n<!-- This is the case of clustering or measurement error, and overlooking issues such as clustering and measurement error can lead to biased and less precise parameter estimates [@McElreath_2020], ultimately diminishing the statistical power of models and increasing the likelihood of committing type I or type II errors when addressing research inquiries. -->\n\n<!-- This has been considered in the literature as a (see https://doi.org/10.1177/1471082X15571817) or a multilevel BTL model (find sources) -->\n\n\n\n<!--   (c) related to case 5, discriminal dispersions of the stimuli are equal, but it is not hard to imagine that certain individuals can produce good quality texts with more precision than other individuals. Example of exaggerated comparison of individuals, university students vs secondary school students. -->\n\n<!--   here we face misspecification in the model -->\n\n\n\n\n<!-- If your scores are not reliable they cannot be valid. People have been employing a model with assumptions that they do not know if those assumptions apply for their cases. And when you do that, the scores you produce most likely will not be reliable, which, in turn, renders them invalid. -->\n\n<!--   [Reliability is a necessary but not sufficient condition for validity. Reliability can exist without validity but validity cannot exist without reliability [@Perron_et_al_2015]]{style=\"color:red;\"}. -->\n\n\n\n## The role and impact of comparison algorithms\n\n<!-- Experimental design -->\n\n<!-- In this regard, although the literature has tested multiple features of the experimental design of the method, such as the comparison algorithm and the number of comparisons, it is not clear where this procedures fit in the whole process of comparison, and what are their implications for the outcome of the method. -->\n\n<!-- @Bramley_et_al_2019 and @Bramley_2015 says adaptivity inflates reliability. present the evidence of bias effects of adaptive algorithms, the not clear view of how many comparisons per (sub)units are required. Adhoc rules of thumb. -->\n\n<!-- @Bramley_2015 -->\n<!-- The implication is that the SSR statistic is worthless as an indicator of the quality / consistency / reliability of a scale constructed from an ACJ study that has involved a significant number of adaptive rounds. With random or fixed rounds, the SSR values were all below 0.25, which would generally be taken as an indicator of failure to create a meaningful scale. To put it another way, a low value of SSR almost certainly indicates low reliability, but a high value of SSR does not necessarily indicate high reliability.  -->\n<!-- This is not to say that the ACJ studies listed in Table 1 (or indeed other studies not listed) were themselves worthless, just that not much should be made of claims about very high reliability in ACJ studies on the basis of high values of the SSR statistic. In fact, many of those studies also showed moderate to high correlations with variables external to the analysis, which were rightly interpreted as evidence of concurrent validity. -->\n<!-- The conclusion is therefore that the SSR statistic is at best misleading and at worst worthless as an indicator of scale reliability whenever a CJ study has involved a significant amount of adaptivity. -->\n\n<!-- @Gray_et_al_2024 entropy-driven active learning pair-selection algorithm to compare stimuli, vs random and no repeating pairs -->\n\n<!-- @DeVrindt_et_al_2024 cold start problem to optimize time efficiency. -->\n\n<!-- @Mikhailiuk_et_al_2021 proposed a fully Bayesian active sampling strategy for pairwise comparisons via Approximate Message Passing and Information Gain Maximization. ASAP computes the full posterior distribution, which is crucial to achieving accurate EIG estimates, and thus the accuracy of active sampling. We recommend ASAP, as it offered the highest accuracy of inferred scores compared to existing methods in experiments with real and synthetic data. -->\n\n<!-- @Verhavert_et_al_2022 The current article proposes a new adaptive selection algorithm using a previously calibrated reference set. Using a reference set should eliminate the reliability inflation. It is proven that this adaptive selection algorithm is more efficient without reducing the accuracy of the results and without increasing the standard deviation of the assessment results. Akin to BIB designs and more specifically to BTIB designs  -->\n\n\n<!-- and issues related to the method's experimental design. These issues can affect the method's reliability, validity, and practical applicability. -->\n\n\n<!-- @Coertjens_et_al_2017 assess reliability and time investment. We conclude that pairwise comparison requires a similar time investment from evaluators as the criterion list method. We want to note that the outcomes in this study depend heavily on the design. First, the time taken for an assessment is strongly determined by the length of the criteria list used and the length of the texts (Breland, 1983). Not adaptive -->\n\n\n<!-- Although the process of pairwise comparisons is quite easy and fast for raters to apply (@Laming_2004; @Pollitt_2004), even without training, the increase in time investment that is needed for CJ decreases its feasibility in educational practice. -->\n\n\n<!-- Messick_1989 talks about efficiency and feasibility for application  -->\n\n<!-- @Bramley_2008 proposes ranking instead of comparisons -->\n\n\n<!-- talk about the number of comparisons @Verhavert_et_al_2019, @Crompvoets_et_al_2022, @Pollitt_2004 -->\n\n\n<!-- @Pollitt_2012b concludes that speed is not related to the quality of assessments in pairwise comparisons -->\n\n\n<!-- All studies use SSR as a measure of reliability -->\n\n\n\n# Theory {#sec-theory}\n<!-- recording 1 -->\n<!-- Part 2; 00:14:30 - 00:21:00 -->\n\n<!-- 3. What is the solution? -->\n\n<!-- Notes:  -->\n<!-- - There is some gain on considering a more integrated overarching systematic way of looking on what happen in DCJ when people compare two stimuli -->\n<!-- - This paper tries to systematically integrate all aspects at play in a single scientific model, we will build the model in a stepwise manner using -->\n<!-- - we will build a scientific model (more theoretical model) that integrates different aspects of the method that are at play when people use DCJ. -->\n\n\n\n## A theoretical model for CJ {#sec-theory-theoretical}\n\n## From theory to statistics {#sec-theory-statistics}\n\n<!-- @Pritikin_2020 and @Gray_et_al_2024 bayesian modeling attempts -->\n\n\n\n# Discussion {#sec-discuss}\n\n## Findings {#sec-discuss-finding}\n\n<!-- Pollitt (2012a) argues that assessors in pairwise comparisons need less training, given intuitive comparison and decision making. However, there is a distinct lack of research on the role of training.  -->\n\n<!-- Due to efficiency of scoring, most of research only colects only one text. This assumes that there is significant homogeneity between text of the same individual, compared to the between individual variability. However, this cannot be known ad-hoc.  -->\n\n## Limitations and further research {#sec-discuss-limitations}\n\n\n\n# Conclusion {#sec-conclusion}\n\n\n\n\n{{< pagebreak >}}\n\n\n\n# Declarations {.appendix .unnumbered}\n\n**Funding:** The project was founded through the Research Fund of the University of Antwerp (BOF).\n\n**Financial interests:** The authors have no relevant financial interest to disclose.\n\n**Non-financial interests:** Author XX serve on advisory broad of Company Y but receives no compensation this role.\n\n**Ethics approval:** The University of Antwerp Research Ethics Committee has confirmed that no ethical approval is required.\n\n**Consent to participate:** Not applicable\n\n**Consent for publication:** All authors have read and agreed to the published version of the manuscript.\n\n**Availability of data and materials:** No data was utilized in this study.\n\n**Code availability:** All the code utilized in this research is available in the digital document located at: [https://jriveraespejo.github.io/paper2_manuscript/](https://jriveraespejo.github.io/paper2_manuscript/).  \n\n**AI-assisted technologies in the writing process:** The authors used ChatGPT, an AI language model, during the preparation of this work. They occasionally employed the tool to refine phrasing and optimize wording, ensuring appropriate language use and enhancing the manuscript's clarity and coherence. The authors take full responsibility for the final content of the publication.\n\n**CRediT authorship contribution statement:** *Conceptualization:* S.G., S.DM., T.vD., and J.M.R.E; *Methodology:* S.DM., T.vD., and J.M.R.E; *Software:* J.M.R.E.; *Validation:* J.M.R.E.; *Formal Analysis:* J.M.R.E.; *Investigation:* J.M.R.E; *Resources:* S.G., S.DM., and T.vD.; *Data curation:* J.M.R.E.; *Writing - original draft:* J.M.R.E.; *Writing - review & editing:* S.G., S.DM., and T.vD.; *Visualization:* J.M.R.E.; *Supervision:* S.G. and S.DM.; *Project administration:* S.G. and S.DM.; *Funding acquisition:* S.G. and S.DM.\n\n<!-- **Acknowledgements:** -->\n\n\n\n{{< pagebreak >}}\n\n\n\n# Appendix {#sec-appendix}\n\n## Appendix A: Ignoring uncertainty {#sec-appendix-A}\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# # simulate units and sub-units\n# USd = sim_units_trait( Un=10,\n#                        Us=c(1,1),\n#                        Ub=c(0,-0.2,0.2),\n#                        Useed = 45789,\n#                        Sn=6,\n#                        Ss=c(0.8,0.8),\n#                        Sb=c(0,0,0),\n#                        Sseed = 9478 )\n# \n# # simulate judges bias\n# Jd = sim_judges_bias( Jn=10,\n#                       Js=c(0.02,0.02),\n#                       Jseed = 79985 )\n# \n# \n# # simulate full comparison data\n# d = cm_full( USd=USd$USd,\n#              Jd=Jd$Jd )\n# \n# \n# # set data in list\n# dL = list_data( d )\n# str(dL)\n```\n:::\n\n\n## Appendix B: The five cases of Thurstone {#sec-appendix-B}\n\n<!-- Thurstone's comparative judgment (CJ) theory [@Thurstone_1927] is composed of two key elements: the discriminal process and the law of comparative judgment.   -->\n\n<!-- In a CJ study evaluating text quality quality of written texts -->\n\n\n\n\n\n\n{{< pagebreak >}}\n\n\n\n# References {.unnumbered}\n\n:::{#refs}\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}