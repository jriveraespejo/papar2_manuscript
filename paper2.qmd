---
title: "Let's talk about Thurstone & Co.: An information-theoretical model for comparative judgments, and its statistical translation"
author:
  - name: 
      given: Jose Manuel
      family: Rivera Espejo
    orcid: 0000-0002-3088-2783
    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/
    email: JoseManuel.RiveraEspejo@uantwerpen.be
    corresponding: true
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Tine
      family: van Daal
      non-dropping-particle: van
    orcid: https://orcid.org/0000-0001-9398-9775
    url: https://www.uantwerpen.be/en/staff/tine-vandaal/
    email: tine.vandaal@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Sven
      family: De Maeyer
      non-dropping-particle: De
    orcid: 0000-0003-2888-1631
    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/
    email: sven.demaeyer@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Steven
      family: Gillis
    orcid: 
    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/
    email: steven.gillis@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Linguistics
        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)
funding: 
  statement: "The project was founded through the Research Fund of the University of Antwerp (BOF)."
keywords:
  - causal inference
  - directed acyclic graphs
  - structural causal models
  - bayesian statistical methods
  - thurstonian model
  - comparative judgement
  - probability
  - statistical modeling
abstract: |
  This study revisits Thurstone's law of comparative judgments (CJ) by addressing two key limitations in traditional approaches. Firstly, it addresses the overreliance on the assumptions of Thurstone's Case V in the statistical analysis of CJ data. Secondly, it addresses the apparent disconnect between CJ's approach to trait measurement and hypothesis testing. We put forward a systematic approach based on causal analysis and Bayesian statistical methods, which results in a model that facilitates a more comprehensive understanding of the factors influencing CJ experiments while offering a robust statistical translation. The new model accommodates unequal dispersions and correlations between stimuli, enhancing the reliability and validity of CJ's trait estimation, thereby ensuring the accurate measurement and interpretation of comparative data. The paper highlights the relevance of this updated framework for modern empirical research, particularly in education and social sciences. This contribution advances current research methodologies, providing a robust foundation for future applications in diverse fields.
key-points:
  - (to do)
date: last-modified
bibliography: references.bib
---

<!-- abstract -->
<!-- recording: Sven and Tine 24.11.25; time: 00:58:20 - 00:59:20 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:11:50 - 00:26:10, (Here we did it!) -->


# Introduction {#sec-introduction}

<!-- recording: Sven 24.10.04; time: 00:00:00 - 00:09:10 -->
<!-- recording: Sven 24.10.04; time: 00:14:30 - 00:21:00 -->
<!-- recording: Sven and Tine 24.10.18; time: 00:04:05 - 00:08:30 -->
<!-- recording: Sven and Tine 24.10.25; time: 00:00:00 - 00:17:00 -->

<!-- 1. Overview of CJ method in assessing traits -->
In *comparative judgment* (CJ) studies, judges assess a specific trait or attribute across different stimuli by performing pairwise comparisons [@Thurstone_1927a; @Thurstone_1927b]. Each comparison produces a dichotomous outcome, indicating which stimulus is perceived to have a higher trait level. For example, when assessing writing quality, judges compare pairs of written texts (the stimuli) to determine the relative writing quality each text exhibit (the trait) [@Laming_2004; @Pollitt_2012b; @Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018_thesis; @Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023].

<!-- and spoken language [@Boonen_et_al_2020]. Additionally, it has been applied to evaluate various competencies, including mathematical problem-solving skills [@Jones_et_al_2015], engineering design skills [@Bartholomew_et_al_2018], build real-time web-based portfolios of performance [@@Kimbell_2012], conceptual understanding in algebra [@Jones_et_al_2019], statistical and English knowledge [@Marshall_et_al_2020], and STEM knowledge and skills [@Bartholomew_et_al_2020]. -->

<!-- 2. What is the effectiveness of CJ -->
Numerous studies have documented the effectiveness of CJ in assessing traits and competencies over the past decade. These studies have highlighted three aspects of the method's effectiveness: its reliability, validity, and practical applicability. Research on reliability suggests that CJ requires a relatively modest number of pairwise comparisons [@Verhavert_et_al_2019; @Crompvoets_et_al_2022] to generate trait scores that are as precise and consistent as those generated by other assessment methods [@Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023]. In addition, the evidence suggests that the reliability and time efficiency of CJ are comparable, if not superior, to those of other assessment methods when employing adaptive comparison algorithms [@Pollitt_2012b; @Verhavert_et_al_2022; @Mikhailiuk_et_al_2021]. Meanwhile, research on the validity of CJ scores indicates their capacity to represent the traits under measurement accurately [@Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018_thesis; @Bartholomew_et_al_2018; @Bouwer_et_al_2023]. Moreover, research on CJ's practical applicability highlights its versatility across both educational and non-educational contexts [@Kimbell_2012; @Jones_et_al_2015; @Bartholomew_et_al_2018; @Jones_et_al_2019; @Marshall_et_al_2020; @Bartholomew_et_al_2020; @Boonen_et_al_2020].

<!-- rubrics [@Coertjens_et_al_2017; @Goossens_et_al_2018]  -->
<!-- holistic benchmark ratings [@Bouwer_et_al_2023] -->

<!-- Adaptive comparison algorithms dynamically present stimuli to judges, based on the results of previous comparisons. They aim to enhance the informativeness of comparisons while optimizing judges' time [@Bramley_2015].  -->

<!-- 3. But what critical issues remain in CJ Research?, what is the organization of the study? -->
Nevertheless, despite the increasing number of CJ studies, the prevalence of unsystematic and fragmented research approaches has left several critical issues unaddressed. The present study primarily focuses on two issues: the overreliance on Thurstone's Case V assumptions in the statistical analysis of CJ data and the apparent disconnect between CJ's approach to trait measurement and hypothesis testing. The following sections begin with a brief overview of Thurstone's theory followed by a detailed examination of these issues. Subsequently, the study introduces a theoretical model for CJ that builds upon Thurstone's theory, alongside its statistical translation, designed to address the two concerns simultaneously.


# Thurstone's theory {#sec-thurstone_theory}
<!-- recording: Sven and Tine 24.11.18; time: 00:04:30 - 00:14:50 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:19:04 - 00:21:37 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:00:35 - 00:06:55 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:30:35 - 00:35:10 -->
<!-- recording: Sven and Tine 24.12.09; time: 00:00:00 - 00:03:20 -->

<!-- 1. Thurstone's Theory of CJ: discriminal process -->
In its most general form, Thurstone’s theory addresses pairwise comparisons wherein a single judge evaluates multiple stimuli [@Thurstone_1927b, pp. 267]. The theory posits that two key factors determine the dichotomous outcome of these comparisons: the discriminal process of each stimulus and their discriminal difference. The *discriminal process* captures the psychological impact each stimulus exerts on the judge or, more simply, his perception of the stimulus trait. The theory assumes that the discriminal process for any given stimulus forms a Normal distribution along the trait continuum [@Thurstone_1927b, pp. 266]. The mode (mean) of this distribution, known as the *modal discriminal process*, indicates the stimulus position on this continuum, while its dispersion, referred to as the *discriminal dispersion*, reflects variability in the perceived trait of the stimulus.

<!-- The psychological continuum or scale is so constructed or defined that the frequencies of the respective discriminal processes for any given stimulus form a normal distribution on the psychological scale. This involves no assumption of a normal distribution or of anything else. The psychological scale is at best an artificial construct. If it has any physical reality, we certainly have not the remotest idea of what it may be like. ... We define the scale in terms of the frequencies of the discriminal processes for any stimulus. This artificial construct, the psychological scale, is so spaced off that the frequencies of the discriminal processes for any given stimulus form a normal distribution on the scale.[@Thurstone_1927b, pp. 266] -->

<!-- 2. Example of discriminal processes -->
@fig-discriminal_process illustrates hypothetical discriminal processes along a quality trait continuum for two written texts. The figure indicates that the modal discriminal process for Text B is positioned further along the continuum than that of Text A $(T_{B} > T_{A})$, suggesting that Text B exhibits higher quality. Additionally, the figure highlights that Text B has a broader distribution compared to Text A, which arises from its larger discriminal dispersion $(\sigma_{B} > \sigma_{A})$.

::: {#fig-thurstone_theory layout-ncol=2}

![Discriminal processes](/images/png/discriminal_process.png){#fig-discriminal_process width=100%}

![Discriminal difference](/images/png/discriminal_difference.png){#fig-discriminal_difference width=100%}

Hypothetical discriminal processes and discriminant difference along a quality trait continuum for two written texts.
:::

<!-- 3. Thurstone's Theory of CJ: discriminal difference -->
However, given that the individual discriminal processes of the stimuli are not directly observable, the theory introduces the *law of comparative judgment*. This law posits that in pairwise comparisons, a judge perceives the stimulus with a discriminal process positioned further along the trait continuum as possessing more of the trait [@Bramley_2008, pp. 251]. This suggests that the relative distance between stimuli, rather than their absolute positions on the continuum, likely defines the outcome of pairwise comparisons. Indeed, the theory assumes that the difference between the underlying discriminal processes of the stimuli, referred to as the *discriminal difference*, determines the observed dichotomous outcome. Furthermore, the theory assumes that because the individual discriminal processes form a Normal distribution on the continuum, the discriminal difference will also conform to a Normal distribution [@Andrich_1978]. In this distribution, the mode (mean) represents the relative separation between the stimuli, and its dispersion indicates the variability of that separation.

<!-- The mode (mean) of this distribution, representing the (average) relative separation, is given by the difference between the modal discriminal processes of the stimuli $S_{BA}=S_{B}-S_{A}$. Meanwhile, the dispersion of the distribution, reflecting the variability in the relative separation, is calculated as $\sigma_{BA} = \sqrt{\sigma_{B}^{2} + \sigma_{A}^{2} - \rho\sigma_{B}\sigma_{A}}$. Here, $\sigma_{B}$ and $\sigma_{A}$ denote the discriminal dispersions of the stimuli, while $\rho$ represents the correlation between their discriminal processes. This correlation quantifies the dependence of the judge's perception of the trait in one stimulus on his perception of the same trait in another. -->

<!-- 4. Example of discriminal difference -->
@fig-discriminal_difference illustrates the distribution of the discriminal difference for the hypothetical texts depicted in @fig-discriminal_process. The figure indicates that the judge perceives Text B as having significantly higher quality than Text A. This conclusion is supported by two key observations: the positive difference between their modal discriminal processes $(T_{B} - T_{A} > 0)$ and the probability area where the discriminal difference distinctly favors Text B over Text A, represented by the shaded gray area denoted as $P(B > A)$. As a result, the dichotomous outcome of this comparison is more likely to favor Text B over Text A.


# The two critical issues in CJ literature {#sec-theory-issues}

This section examines the two critical issues in the CJ literature that serve as the primary focus of the present study. The first is related to the overreliance on Thurstone's Case V assumptions in the statistical analysis of CJ data. The second concern with the apparent disconnect between CJ's approach to trait measurement and hypothesis testing.

## The Case V and the statistical analysis of CJ data {#sec-theory-issue1}

<!-- recording: Sven and Tine 24.10.25; time: 00:31:10 - 00:52:20 -->
<!-- recording: Sven and Tine 24.11.12; time: 00:00:00 - 00:00:00 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:00:25 - 00:04:30 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:14:50 - 00:19:04 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:21:37 - 00:47:20 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:06:55 - 00:24:50 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:35:10 - 00:49:30 -->
<!-- recording: Sven and Tine 24.12.09; time: 00:03:20 - 00:08:10 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:00:00 - 00:06:10 -->

<!-- 1. What is the problem with the general form -->
Thurstone noted from the outset that the general form of the theory, as outlined in @sec-thurstone_theory, gave rise to a problem of trait scaling. The model required estimating more "unknown" parameters than the available pairwise comparisons [@Thurstone_1927b, pp. 267]. To address this issue and facilitate the practical implementation of the theory, he developed five cases derived from this general form, each case progressively incorporated additional simplifying assumptions into the model.

<!-- 2. Thurstone's Cases and their simplifying assumptions -->
In Case I, Thurstone postulated that pairs of stimuli would maintain a constant correlation across all comparisons. In Case II, he allowed multiple judges to undertake comparisons instead of confining evaluations to a single judge. In Case III, he posited that there was no correlation between stimuli. In Case IV, he assumed that the stimuli exhibited similar dispersions. Finally, in Case V, he replaced this assumption with the condition that stimuli had equal discriminal dispersions. @tbl-thurstone_cases summarizes the assumptions of the general form and the five cases. For a detailed discussion of these cases and their progression, refer to @Thurstone_1927b and @Bramley_2008 [pp. 248–253].

<!-- In Case II, Thurstone assumes that "each judge compares each stimulus with every other stimulus only once" [@Thurstone_1927b, pp. 268]. -->

![Thurstones cases and their asumptions](/images/png/thurstone_cases.png){#tbl-thurstone_cases width=100%}

<!-- 3. The Case V and its simpler statistical representation: the BTL model -->
Notably, despite relying on the most extensive set of simplifying assumptions [@Bramley_2008, pp. 253; @Kelly_et_al_2022, pp. 677], Case V remains the most widely used case in the CJ literature. This popularity stems mainly from its simplified statistical representation in the Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959]. The BTL model mirrors the assumptions of Case V, with one notable distinction: whereas Case V assumes a Normal distribution for the stimuli's discriminal processes, the BTL model uses the more mathematically tractable Logistic distribution [@Andrich_1978; @Bramley_2008, pp. 254] (see @tbl-thurstone_cases). This substitution has little impact on the model's estimation or interpretation, as the Normal and Logistic distributions exhibit analogous statistical properties, differing only by a scaling factor of approximately $1.7$ [@vanderLinden_et_al_2017_I, pp. 16].

<!-- the mathematical function linking dichotomous outcomes to trait scores -->

<!-- Model misspecification happens when the set of probability distributions considered by the statistician does not include the distribution that generated the observed data. -->

<!-- ::: {#fig-logistic_vs_normal layout-nrow=2} -->

<!-- ![Probability density](/images/png/density.png){#fig-density width=70%} -->

<!-- ![Cummulative probability](/images/png/cummulative.png){#fig-cumulative width=70%} -->

<!-- Probability density and cumulative probability of the logistic and Normal distributions. -->
<!-- ::: -->

<!-- 4. But what are limitations of Case V (and the BTL model)? -->
However, Thurstone originally developed Case V to provide a "rather coarse scaling" of traits [@Thurstone_1927b, pp. 269], prioritizing statistical simplicity over precision in trait measurement [@Kelly_et_al_2022, pp. 677]. He explicitly warned against its untested application, stating that its use "should not be made without (an) experimental test" [@Thurstone_1927b, pp. 270]. Furthermore, he acknowledged that some assumptions could prove problematic when researchers assess complex traits or heterogeneous stimuli [@Thurstone_1927a, pp. 376]. Consequently, given that modern CJ applications frequently involve such traits and stimuli, two main assumptions of Case V and, by extension, of the BTL model may not consistently hold in theory or practice, namely the assumption of equal dispersion and zero correlation between stimuli.

<!-- Adding assumptions simplifies the formula and improves its tractability, but one cannot place as much confidence in the outputs of the formula if those assumptions are not met [@Kelly_et_al_2022, pp. 677]. -->


### The assumption of equal dispersions between stimuli {#sec-theory-issue1a}

<!-- recording: Sven and Tine 24.12.09; time: 00:08:10 - 00:37:00 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:06:10 - 00:08:50 -->

<!-- 1. What does the equal dispersion between stimuli imply? -->
According to the theory, discrepancies in the discriminal dispersions of stimuli shape the distribution of the discriminal difference, exerting a direct influence on the outcome of pairwise comparisons. @fig-dispersion presents a thought experiment to illustrate this idea. In this experiment, a researcher can observe the discriminal processes for the texts depicted in @fig-discriminal_process. Furthermore, the figure assumes that the discriminal dispersion for Text A remains constant and that the texts are uncorrelated $(\rho=0)$. The figure reveals that an increase in the uncertainty associated with the perception of Text B in comparison to Text A, $(\sigma_{B}-\sigma_{A})$, broadens the distribution of their discriminal difference. This broadening affects the probability area where the discriminal difference distinctly favors Text B over Text A, expressed as $P(B > A)$, ultimately influencing the comparison outcome. Additionally, the figure reveals that when the discriminal dispersions of the texts are equal $(\sigma_{B}-\sigma_{A}=0)$, the discriminal difference is more likely to favor Text B over Text A (shaded gray area), compared to situations where their dispersions differ.

::: {#fig-caseV_issues layout-ncol=2}

![Discrepancies in the dispersions of stimuli](/images/png/dispersion.png){#fig-dispersion width=100%}

![Correlation between stimuli](/images/png/correlation.png){#fig-correlation width=100%}

The effect of dispersion discrepancies and stimulus correlation on the distribution of the discriminal difference.
:::

<!-- 2. But this is not the scenario we observe -->
In experimental practice, however, this process occurs in reverse. Researchers first observe the comparison outcome and then use the BTL model to infer the discriminal difference between the stimuli and their respective discriminal processes [@Thurstone_1927a, pp. 373]. Therefore, the outcome's ability to reflect the "true" differences between stimuli largely depends on the validity of the model's assumptions [@Kohler_et_al_2019, pp. 150], particularly the assumption of equal dispersions. For instance, when researchers observe a sample of outcomes favoring Text B over Text A and correctly assume equal dispersions between the texts, the BTL model estimates a discriminal difference distribution that accurately represents the "true" discriminal difference of the texts. This scenario is illustrated in @fig-dispersion, where the model's discriminal difference distribution aligns with the "true" distribution, represented by the thick continuous line corresponding to $\sigma_{B}-\sigma_{A}=0$. The accuracy of these discriminal difference ensures reliable estimates for the texts’ discriminal processes [(citation needed?)]{style="color:red;"}. 

<!-- In experimental practice the procedure is the reverse of this hypothesis because the frequencies are known first experimentally, and from these frequencies we construct the psychological continuum. [@Thurstone_1927a, pp. 373] -->

<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are. [@Kohler_et_al_2019, pp. 150] -->

<!-- 3. But does it hold?  -->
However, Thurstone argued that the assumption of equal dispersions may not be applicable when researchers assess complex traits or heterogeneous stimuli [@Thurstone_1927a, pp. 376], as these traits and stimuli can introduce judgment discrepancies due to their unique features [@vanDaal_et_al_2016; @Lesterhuis_2018; @Chambers_et_al_2022]. Indeed, evidence of this violation may already be present in the CJ literature in the form of misfit statistics, which measure judgment discrepancies associated with specific stimuli [@Pollitt_2004, pp. 12; @Goossens_et_al_2018, pp. 20]. For example, labeling texts as "misfits" indicates that comparisons involving these texts result in more judgment discrepancies than those involving other texts [@Pollitt_2012a; @Pollitt_2012b; @vanDaal_et_al_2016; @Goossens_et_al_2018]. These discrepancies, in turn, suggest that the discriminal differences for "misfit" texts have broader distributions, indicating that their discriminal processes may also exhibit more variation than that of other texts. A similar line of reasoning applies to the concept of "misfit" judges, whose evaluations deviate substantially from the shared consensus due to the unique characteristics of the stimuli or the judges themselves. These "misfit" judges and their associated deviations can give rise to additional statistical and measurement issues, which we discuss in more detail in @sec-theory-issue1b.

<!-- Of these, the most questionable is the one that the discriminal dispersions of all the objects are equal. Thurstone clearly did not expect this to hold for any but the most simple stimuli. The scripts used in cross-moderation exercises are obviously far more complex than any used by Thurstone, so it seems naive to expect this assumption to hold here [@Bramley_2008]. -->

<!-- It is probably true that this variability of the discriminal dispersion on the psychological continuum is of relatively less serious importance in dealing with strictly homogeneous stimulus series, but it becomes a serious factor in dealing with less conspicuous attributes or with less homogeneous stimulus series, such as handwriting specimens, English compositions, sewing samples, oriental rugs. In measurements of the type known as judgment scales the discriminal dispersion on the psychological continuum becomes one of the unknowns to be determined as well as the scale value of the specimen. Every specimen in such a series presents two unknown values to be determined, namely, the scale value of its modal discriminal process on the psychological continuum and its discriminal dispersion. [@Thurstone_1927a, pp. 376] -->

<!-- For instance, in evaluating creativity, a student might complete an assignment in a highly creative but unexpected manner. Judges, unprepared for such originality, may produce more divergent evaluations of the assignment. These increased discrepancies in judgments suggest that the discriminal difference associated with the assignment has a broader dispersion, indicating greater variation in the discriminal process for this assignment compared to others. -->

<!-- "weak" writers consistently produce texts of low quality in all aspects that determine the quality of a text, such as grammatical accuracy, organization, and language use. In such cases, judges typically agree on their inferior quality, leading to a clear disfavoring of these texts compared to others. This agreement ultimately imply narrow dispersions for the discriminal differences related to these texts and, by extension, narrow discriminal processes for them. However, as texts improve along the trait continuum, with certain aspects showing improvement and others reaming unaltered, these variations introduce uncertainty into the judgments. Now, since judges often rely on various intricate characteristics of the texts to form their judgments [@vanDaal_et_al_2016; @Lesterhuis_2018; @Chambers_et_al_2022], these changes lead to greater discrepancies in their evaluations. This divergence ultimately imply broader discriminal differences and, by extension, more varied discriminal processes for the texts. -->

<!-- So it seem that the extreme of the discriminal process distribution of the stimuli have higher reliability than the center? -->

<!-- If a portfolio’s WMS exceeds the criterion of mean plus two standard deviations, this means the judges did not judge it consistently, some considering it ‘better’ than others did. [@Pollitt_2012a, pp. 165] -->

<!-- Representations with a large infit are representations which lead to more inconsistent judgments [@Goossens_et_al_2018, pp. 20] -->

<!-- a misfit statistic. Essentially this reports the amount of inconsistency in the various judgements that have been made of that script. It can act as a flag identifying scripts that judges find difficult to judge [@Pollitt_2004, pp. 12] -->

<!-- 4. So, what happens when the assumption does not hold? -->
Thus, model misspecification, in the form of an erroneous assumption of equal dispersions between stimuli, can give rise to significant statistical and measurement issues. For instance, the model may overestimate the degree to which the outcome accurately reflects the "true" discriminal differences between stimuli. This overestimation can result in researchers drawing spurious conclusions about these differences [@McElreath_2020, pp. 370] and, by extension, about the underlying discriminal processes of stimuli. @fig-dispersion also illustrates this issue when the model's discriminal difference distribution aligns with the thick continuous line for $\sigma_{B}-\sigma_{A}=0$, while the "true" discriminal difference follows any discontinuous line where $\sigma_{B}-\sigma_{A} \neq 0$. Additionally, if researchers recognize that misfit statistics highlight these critical differences in dispersions, the conventional CJ practice of excluding stimuli based on these statistics [@Pollitt_2012a; @Pollitt_2012b; @vanDaal_et_al_2016; @Goossens_et_al_2018] can unintentionally discard valuable information. Such exclusions can introduce bias into trait estimates [@Zimmerman_1994; @McElreath_2020, chap. 12]. The direction and magnitude of these biases are often unpredictable, as they depend on which stimuli are excluded from the analysis.

<!-- Moreover, excluding data using ad hoc univariate procedures can compound these issues by discarding potentially valuable information, further exacerbating the bias [@Zimmerman_1994; @McElreath_2020] -->

<!-- But ignoring over-dispersion can also lead to all of the same problems as ignoring any predictor variable. Heterogeneity in counts can be a confound, hiding effects of interest or producing spurious inferences. [@McElreath_2020, pp. 370] -->


### The assumption of zero correlation between stimuli {#sec-theory-issue1b}

<!-- recording: Sven and Tine 24.12.17; time: 00:08:50 - 00:10:30 -->

<!-- 1. What does the zero correlation between stimuli imply? -->
The correlation, represented by the symbol $\rho$, measures how much a judge's perception of a specific trait in one stimulus depends on their perception of the same trait in another. As with the discriminal dispersions, this correlation shapes the distribution of the discriminal difference, directly impacting the outcomes of pairwise comparisons. @fig-correlation presents a similar thought experiment as in @sec-theory-issue1a to illustrate this idea. The illustration now assumes that the discriminal dispersions for both texts remain constant. The figure reveals that as the correlation between the texts increases, the distribution of their discriminal difference becomes narrower. This narrowing affects the area under the curve where the discriminal difference distinctly favors Text B over Text A, denoted as $P(B > A)$, thus influencing the comparison outcome. Furthermore, the figure shows that when two texts are independent or uncorrelated $(\rho=0)$, their discriminal difference is less likely to favor Text B over Text A (shaded gray area) compared to scenarios where the texts are highly correlated.

<!-- "It is a safe assumption that when the stimulus series is very homogeneous with no distracting attributes, the correlation between discriminal deviations is low and possible even zero" [@Thurstone_1927b, pp. 268]. -->

<!-- 2. But this is not the scenario we observe -->
Off course, in experimental practice, researchers approach this process in reverse. They begin by observing the sample of outcomes favoring Text B over Text A and then use the BTL model to estimate the discriminal difference and the discriminal processes of the stimuli. Given that the BTL model assumes independent discriminal processes across comparisons, if this assumption holds, then the model estimates a discriminal difference distribution that accurately reflects the "true" discriminal difference of the texts. This scenario is also illustrated in @fig-correlation when the discriminal difference distribution of the model aligns with the "true" distribution, represented by the thick continuous line corresponding to $\rho=0$. Once more, the estimation accuracy of the discriminal difference ensures reliable estimates for the discriminal processes of the texts [(citation needed?)]{style="color:red;"}.

<!-- It then follows that the outcome's ability to represent the "true" differences between stimuli largely depends on the validity of the assumption of zero correlation. -->

<!-- 2. But does it hold?  -->
Notably, Thurstone attributed the independence of stimuli to the cancellation of potential judges' biases. He argued that this cancellation resulted from two opposing and equally weighted effects occurring during pairwise comparisons [@Thurstone_1927b, pp. 268]. @Andrich_1978 provided a mathematical demonstration of this cancellation using the BTL model under the assumption of discriminal processes with additive biases. However, it is easy to imagine at least two scenarios in which the zero correlation assumption is almost certainly invalid: when the pairwise comparison involves multidimensional, complex traits with heterogeneous stimuli and when an additional hierarchical structure is relevant to the stimuli.

<!-- 3. The first scenario where the assumption does not hold -->
In the first scenario, the intricate aspects of multidimensional, complex traits may introduce dependencies between the stimuli due to certain judges' biases that resist cancellation. Research on text quality suggests that when judges evaluate these traits, they often rely on various intricate characteristics of the stimuli to form their judgments [@vanDaal_et_al_2016; @Lesterhuis_2018; @Chambers_et_al_2022]. These additional relevant characteristics, which are unlikely to be equally weighted or opposing, can exert an uneven influence on judges' perceptions, creating biases in their judgments and, ultimately, introducing dependencies between stimuli [@vanderLinden_et_al_2017_II, pp. 346]. For example, this could occur when a judge assessing the argumentative quality of a text places more weight on its grammatical accuracy than other judges, thereby favoring texts with fewer errors but weaker arguments. While direct evidence for this particular scenario is lacking, studies such as @Pollitt_et_al_2003 demonstrate the presence of such biases, supporting the notion that the factors influencing pairwise comparisons may not always cancel out.

<!-- If the test taker’s position on one latent trait is fixed, the assumption of local stochastic independence requires the association between the responses to the items to vanish. Suppose the assumption is violated and more than one dimension is necessary to describe the test takers’ position in the latent space. The association between the responses to the items given one proficiency parameter does then not vanish. [@vanderLinden_et_al_2017_II, pp. 346]. -->

<!-- research shows that, in the presence of these traits and stimuli, the accuracy of the judges' trait perception is influenced by the rank-order distance of the stimuli [@vanDaal_et_al_2017; @Gijsen_et_al_2021], a coarse measure of the relative positioning of the stimuli within the trait continuum. -->

<!-- 4. The second scenario where the assumption does not hold -->
In the second scenario, the shared context or inherent connections created by additional hierarchical structures may further introduce dependencies between stimuli, a statistical phenomenon commonly known as clustering [@Everitt_et_al_2010]. Despite the CJ literature acknowledging the existence of such hierarchical structures, the statistical handling of this additional source of dependence between stimuli has been inadequate. For instance, when CJ data incorporates multiple samples of stimuli from the same individuals, researchers frequently rely on (average) estimated BTL scores to conduct subsequent analyses and tests at the individual hierarchical level [@Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021]. However, this approach can introduce additional statistical and measurement issues, which we discuss in greater detail in @sec-theory-issue2.

<!-- no study explicitly proposes that this assumption could also be violated due to the presence of an additional hierarchical (grouping) structure relevant to the texts. One such scenario might arise, for example, when comparing texts produced by university and secondary school students. In this case, university students may consistently (or more precisely) produce higher-quality texts, while secondary school students, who exhibit a broader range of writing abilities, would show greater variability in the quality of their texts. Although this example is somewhat contrived, it effectively illustrates how assuming equal dispersions across texts can overlook meaningful differences in the reliability of text quality across groups or individuals. -->

<!-- 5. But what are the challenges when this assumption is violated? -->
In any case, similar to @sec-theory-issue1a, model misspecification due to an erroneous assumption of zero correlation between stimuli can lead to significant statistical and measurement issues. For instance, the model may over- or underestimate how accurately the outcome reflects the "true" discriminal differences between stimuli. Such inaccuracies can result in spurious inferences about these differences and, by extension, about the stimuli's discriminal processes. This scenario is also illustrated by @fig-correlation, when the model's discriminal difference distribution aligns with the thick continuous line for $\rho=0$, while the "true" discriminal difference follows any discontinuous line where $\rho \neq 0$.

The misspecification may arise from neglecting additional relevant traits, excluding judges based on misfit statistics, or ignoring hierarchical (grouping) structures. Neglecting relevant traits, such as judges' biases, can cause dimensional mismatches in the BTL model, artificially inflating the trait's reliability [@Hoyle_et_al_2023, pp. 341] or, worse, introducing bias into the trait's estimates [@Ackerman_1989]. Excluding judges based on misfit statistics risks discarding valuable information, which may further bias the trait's estimates [@Zimmerman_1994; @McElreath_2020, chap. 12]. Finally, ignoring hierarchical structures may reduce the precision of model parameter estimates, potentially amplifying the overestimation of the trait's reliability [@Hoyle_et_al_2023, pp. 482].

<!-- To show the practical consequences, in Figure 18.1, we present the test information for the two models; clearly, the information is positively biased when the multidimensional data are forced into a unidimensional IRT model. Moreover, in this same figure, we show the test response curves (how expected scores change as a function of trait level) for the two models; again, they, clearly, are not overlapping. The estimated implication is that if one applied a unidimensional IRT model, psychometric information is inflated due to the multidimensionality and examinee standard errors, which are the inverse square root of information, are too small. [@Hoyle_et_al_2023, pp. 340-341] -->

<!-- Accounting for measurement error in defining latent variables improves the accuracy of the model’s estimated structural parameters between the latent constructs, which in turn can provide a stronger test of a proposed theoretical model. [@Hoyle_et_al_2023, pp. 482] -->


## The disconnect between trait measurement and hypothesis testing {#sec-theory-issue2}

<!-- recording: Sven 24.10.04; time: 00:14:30 - 00:21:00 -->
<!-- recording: Sven and Tine 24.10.18; time: 00:08:30 - 00:14:55 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:49:30 - 00:53:30 -->

<!-- 1. The BTL model as a measurement model for estimating latent traits -->
Building on the previous section, it is clear that, despite its limitations, the BTL model is commonly used as a measurement model in CJ assessments. A measurement model specifies how manifest variables contribute to the estimation of latent variables [@Everitt_et_al_2010]. For example, when evaluating writing quality, researchers use the BTL model to process the dichotomous outcomes resulting from the pairwise comparisons (the manifest variables) to estimate scores that reflect the underlying level of writing quality (the latent variable) [@Laming_2004; @Pollitt_2012b; @Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018_thesis; @Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023]. 

<!-- 2. Utilizing BTL Scores for further analysis and hypothesis testing -->
Researchers then typically use these estimated BTL scores, or their transformations, to conduct additional analyses or hypothesis tests. For example, these scores have been used to identify 'misfit' judges and stimuli [@Pollitt_2012b; @vanDaal_et_al_2016; @Goossens_et_al_2018], detect biases in judges' ratings [@Pollitt_et_al_2003; @Pollitt_2012b], calculate correlations with other assessment methods [@Goossens_et_al_2018; @Bouwer_et_al_2023], or test hypotheses related to the underlying trait of interest [@Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021].

<!-- 3. But what are the challenges in using BTL scores for further analysis? -->
However, the statistical literature advises caution when using estimated scores for additional analyses and tests. A key consideration is that BTL scores are parameter estimates that inherently carry uncertainty. Ignoring this uncertainty can bias the analysis and reduce the precision of hypothesis tests. Notably, the direction and magnitude of such biases are often unpredictable. Results may be attenuated, exaggerated, or remain unaffected depending on the degree of uncertainty in the scores and the actual effects being tested [@Kline_et_al_2023, pp. 25; @Hoyle_et_al_2023, pp. 137]. Finally, the reduced precision in hypothesis tests diminishes their statistical power, increasing the likelihood of committing type-I or type-II errors [@McElreath_2020]. 

<!-- A type-I error occurs when a *true* null hypothesis is incorrectly rejected, while a type-II error occurs when a *false* null hypothesis is incorrectly accepted [@Everitt_et_al_2010]. -->

In aggregate, researchers' inadequate handling of violations to the assumptions of equal dispersion and zero correlation between stimuli, coupled with the apparent disconnect between CJ's approach to trait measurement and hypothesis testing, can potentially compromise the reliability of the trait estimates and, by extension, their validity [@Perron_et_al_2015, pp. 2]. Consequently, adopting a more systematic and integrated approach to handling these assumptions and examining the factors influencing CJ experiments could offer several statistical and measurement benefits, including the ability to address these issues.

<!-- Reliability is a necessary but not sufficient condition for validity. Reliability can exist without validity but validity cannot exist without reliability [@Perron_et_al_2015, pp. 2]. -->

<!-- People have been employing a model with assumptions that they do not know if those assumptions apply for their cases. -->



<!-- ## The diverse assessment design features and their role on reliability and validity {#sec-theory-issue3} -->
<!-- Do not include yet!, until you see if you need it when you write about the next section -->
<!-- recording: Sven and Tine 24.11.18; time: 00:47:20 - 00:56:41 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:53:30 - 01:00:00 -->



# Updating the theoretical and statistical model {#sec-theory}

This section uses the structural approach to causal inference [@Pearl_2009; @Pearl_et_al_2016] to articulate a theoretical model that captures the core principles of Thurstone's theory. The model also incorporates various assessment design features relevant to CJ experiments, such as the selection of judges, stimuli, and comparisons. Finally, the section employs Bayesian inference methods to transform these theoretical and practical elements into a statistical model that facilitates the analysis of pairwise comparison data. See @sec-appendix for an overview of the statistical and causal inference concepts required for the development of this section.


## The theoretical model {#sec-theory-theoretical}

The theoretical model uses structural causal models (SCMs) and directed acyclic graphs (DAGs) [@Pearl_2009; @Pearl_et_al_2016; @Gross_et_al_2018; @Neal_2020] to formally and graphically represent the assumed causal structure of the CJ system. First, *the population model* is created to represent a conceptual population of CJ experiments. The model then integrates various assessment design features relevant to CJ experiments, leading to the development of *the sample-comparison model*.


### The population model {#sec-theory-theoretical_P}
<!-- []{style="color:red;"} -->

<!-- general development -->
<!-- recording: Sven 24.10.04; time: 00:21:00 - 00:34:10 -->
<!-- recording: Sven 24.10.04; time: 00:41:00 - 00:46:00 -->
<!-- recording: Sven and Tine 24.10.18; time: 00:00:00 - 00:04:05 -->
<!-- recording: Sven and Tine 24.11.25; time: 01:00:00 - 01:08:40 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:26:10 - 00:54:00 -->

<!-- comparison mechanism as missing mechanism -->
<!-- recording: Sven 24.10.04; time: 00:09:10 - 00:14:30 -->
<!-- recording: Sven 24.10.04; time: 00:34:10 - 00:41:00 -->

In this section we focus on the identification of several parameters of interest from the theoretical model, together with various assessment design features relevant to CJ experiments. The main reason to focus on identification is that if these parameters cannot be identified using "infinite" and error free data, we certainly cannot learn anything about it using finite data. So, for the time being, we assume large samples and error-free measurements [@Schuessler_et_al_2023, pp. 5]

<!-- In general terms, causal graphs encode a researcher’s assumptions about the causal process that generated the data in a population of interest [@Schuessler_et_al_2023, pp. 4] -->

<!-- The causal assumptions encoded in a DAG constitute the theoretical model on which identification analysis rests. Identification analysis is concerned with determining whether or not the true value of a parameter can be estimated using the assumptions in the model (graph), regardless of random variability in the data due to small samples [@Schuessler_et_al_2023, pp. 4]. -->


Assuming population data or more commonly known as census data, we ...

The (latent) discriminal difference of the stimuli directly determines the (manifest) outcome of the pairwise comparisons

The (latent) "perceived" discriminal processes for the stimuli directly determines their discriminal difference

The (latent) "true" discriminal processes for the stimuli and the judges' biases directly determines their (latent) "perceived" discriminal processes


![](/images/png/CJ_TM_01.png){#fig-CJ_TM_01 width=23%}

![](/images/png/CJ_TM_02.png){#fig-CJ_TM_02 width=32%}

![](/images/png/CJ_TM_03.png){#fig-CJ_TM_03 width=45%}

![](/images/png/CJ_TM_04.png){#fig-CJ_TM_04 width=45%}


without loosing generality, the (latent) "perceived" and "true" discriminal processes for the stimuli can be depicted in a vector for each judge, as in  


![](/images/png/CJ_TM_05.png){#fig-CJ_TM_05 width=44%}

![](/images/png/CJ_TM_06.png){#fig-CJ_TM_06 width=59%}

![](/images/png/CJ_TM_07.png){#fig-CJ_TM_07 width=68%}

![](/images/png/CJ_TM_08.png){#fig-CJ_TM_08 width=68%}

![](/images/png/CJ_TM_09.png){#fig-CJ_TM_09 width=68%}

![](/images/png/CJ_TM_10.png){#fig-CJ_TM_10 width=68%}

<!-- include subject specific covariates [@Casalicchio_et_al_2015] -->



### The sample-comparison model {#sec-theory-theoretical_SC}

Considering the sampling mechanism

![](/images/png/CJ_TM_11.png){#fig-CJ_TM_11 width=80%}

![](/images/png/CJ_TM_12.png){#fig-CJ_TM_12 width=80%}

<!-- The condition of case selection to be independent from Y is always met in experiments because the Y is not realized before the experiment starts. [@Kohler_et_al_2019, pp. 160] -->

Considering comparison mechanisms

![](/images/png/CJ_TM_13.png){#fig-CJ_TM_13 width=90%}

![](/images/png/CJ_TM_14.png){#fig-CJ_TM_14 width=90%}

![](/images/png/CJ_TM_15.png){#fig-CJ_TM_15 width=90%}


<!-- It is assumed that the single observer compares each pair of stimuli a "sufficient number of times" so that a proportion, P(A>B), may be determined for each pair of stimuli [@Thurstone_1927b, pp. 267] -->



## From theory to statistics {#sec-theory-statistics}

<!-- recording: Sven 24.10.04; time: 00:46:00 - 01:01:00 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:24:50 - 00:30:35 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:49:30 - 00:53:30 -->

<!-- 2. What are the benefits of Bayesian inference?-->
Bayesian inference procedures offer three key advantages. First, they are well-suited to handling complex and overparameterized models, enabling researchers to estimate models where the number of parameters exceeds the number of observations for estimation [@Baker_1998; @Kim_et_al_1999]. Second, they allow researchers to incorporate prior information, which helps constrain parameters within specified bounds. This capability addresses challenges such as non-convergence or improper parameter estimation that often arise in complex models when analyzed with frequentist methods [@Martin_et_al_1975; @Seaman_et_al_2011]. Finally, Bayesian methods are particularly effective at drawing inferences from small sample sizes, where relying on the asymptotic properties of frequentist approaches may not be justified [@Baldwin_et_al_2013; @Lambert_et_al_2006; @Depaoli_2014].


<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are [@Kohler_et_al_2019, pp. 150] -->


<!-- @Pritikin_2020 and @Gray_et_al_2024 bayesian modeling attempts -->

<!-- 6. So, how do we mitigate these risks? -->
<!-- Fortunately, the statistical literature offers a solution to address the abovementioned issues. This solution involves using models that extend traditional approaches to account for the different variability in the stimuli, referred to as over-dispersed models [@McElreath_2020, chap. 12]. -->

<!-- 11. How to solve the violation of the assumption? -->
<!-- Fortunately, the same literature offers solutions for addressing these issues. @Andrich_1978 and @Wainer_et_al_1978 recommend integrating judges' biases into the BTL model. Moreover, the literature advocates for the incorporation of relevant hierarchical structures into the statistical model to account for these dependencies. Together, these additions can result in a model resembling a Multilevel Structural Equation Model (MSEM) [@Hoyle_et_al_2023, chap. 26] combined with a multidimensional or two-parameter logistic Item Response Theory (IRT) model [@Hoyle_et_al_2023, chap. 15], depending on the theoretical and statistical treatment of judges' biases. -->

<!-- Brennen generalizability theory, generalize conclusions over groups. To generalize over judges, you need to estimate them. Akin to Frisch-Wough-Lovel theorem for latent variables?. -->

<!-- 4. So, how do we mitigate these risks? -->
<!-- To mitigate these risks, principles from Structural Equation Modeling (SEM) [@Hoyle_et_al_2023, pp. 138] and IRT [@Fox_2010, chap. 6; @vanderLinden_et_al_2017_I, chap. 24] recommend conducting these analyses and tests within a structural model. A structural model specifies how different manifest or latent variables influence the latent variable of interest [@Everitt_et_al_2010]. This approach allows analyses that can account for both the BTL scores and their uncertainties simultaneously, rather than treating them as separate elements.  -->

<!-- Remember: the "mitigate" paragraph have the purpose of being the design principles that will guide the development of the theoretical and statistical model. -->



<!-- This means that the cancellation of judges' biases may not hold in theory or practice, and that judges' biases may depend on the stimuli, by means of an interaction (but present) or because the judges works as a confounder -->

<!-- Using assumptions from IRT [@deAyala_2009, p. 20-21], we are assuming a multidimensional model, that violates the local independence assumption -->

<!-- [@deAyala_2009, p. 291-29] think about indeterminancies in MIRT. to solve metric indeterminancy you commonly fix a mu=0, and s=1, but for rotational indeterminancy, you need to define (maybe) orthogonality between units traits and judges bias -->


<!-- The correlation $\rho$, considered above is not the kind of correlation considered by Bock (1958) in studies of preference and choice of objects. The Bock correlation arises from a specific interaction between a subject and an item because the subject has a particular "preference", such as a taste preference, for the object. This preference for the object is then reflected in its comparisons with all other objects. However, it is less likely that subjects would have such particular preferences for some items in a test and, in any case, the assumption is open to empirical checking [@Andrich_1978, pp. 455]. -->


# Discussion {#sec-discuss}

## Findings {#sec-discuss-finding}

<!-- recording: Sven and Tine 24.11.25; time: 00:56:10 - 00:56:10 -->

<!-- "If Thurstone’s Law is to be used in support of comparative judgment for assessment, his theory must be extended to cover the uses and applications that are required for assessment purposes." [@Kelly_et_al_2022, pp. 678] -->


<!-- Pollitt (2012a) argues that assessors in pairwise comparisons need less training, given intuitive comparison and decision making. However, there is a distinct lack of research on the role of training.  -->

<!-- Due to efficiency of scoring, most of research only collects only one text. This assumes that there is significant homogeneity between text of the same individual, compared to the between individual variability. However, this cannot be known ad-hoc.  -->


<!-- (Is this a validity contention?) -->
<!-- Furthermore, it is not inconceivable that the selection of a particular group of judges used to perform the pairwise comparison could result in an incomplete depiction of the dimensions and complexity of the trait. Previous research has highlighted that factors such as age, culture, and education [@Kelly_et_al_2022, pp. 683], as well as individual differences among judges [@Gill_et_al_2013; @vanDaal_et_al_2017; @vanDaal_2020], could influence judgment accuracy, thereby affecting the "shared consensus" of the trait measurement. As @Kelly_et_al_2022 noted [pp. 683], “Would the aggregate view of young, British-Asian men always be the same as the aggregate view of older, black women?” -->

<!-- Such differences may not be detected through analyses of bias and misfit. McMahon and Jones (2015) found differences between students and teachers in what was valued in assessments of understanding of a chemistry experiment. Where students prioritized factual recall, teachers prioritized scientific explanation. Both groups produced highly reliable scales (reliability estimates of .893 for students, and .874 for teachers). Although, in this case, a clear argument as to whose consensus should take priority can be made, it demonstrates the existence of different, but equally reliable, sets of consensuses depending on who is asked. [@Kelly_et_al_2022, pp. 683] -->


<!-- "Another challenge to the intrinsic validity argument is that the aggregate approach and valuing of diversity in expert views (Van Daal et al., 2019) is in tension with the idea of removing misfitting judges (Pollitt, 2012a). If someone is considered an expert, and the validity of comparative judgment rests on the collective expertise of a community of practice, the decision to remove them and discard their judgments can only be justifiable on the assumption that those judgments do not reflect their expertise. ... It is thus unclear whether or not this divergence is welcomed." [@Kelly_et_al_2022, pp. 681] -->

<!-- We advocate for the no removal of judges, but rather identify them and treat the data with the appropriate model, so these 'misfits' do not affect the measurement of the trait -->



## Limitations and further research {#sec-discuss-limitations}


<!-- The field of comparative judgment, while growing, is still relatively small, and at present we do not have compelling answers to fundamental questions such as: how many judges do we need? Who should judge? How many judgments should they make? And crucially, how can we be confident that they are basing their judgments on acceptable criteria? If judges are not using construct-relevant criteria, then the argument that comparative judgments are necessarily valid cannot be upheld. We recognise that there is unlikely to be a single answer to these questions for all the cases in which comparative judgment may be used. However, work to derive some general principles for good practice would be valuable. [@Kelly_et_al_2022, pp. 683] -->

<!-- @Bramley_2008 proposes ranking instead of comparisons -->


# Conclusion {#sec-conclusion}



{{< pagebreak >}}

# Declarations {.unnumbered .appendix appendix-style=plain}

**Funding:** The project was founded through the Research Fund of the University of Antwerp (BOF).

**Financial interests:** The authors have no relevant financial interest to disclose.

**Non-financial interests:** The authors have no relevant non-financial interest to disclose.

**Ethics approval:** The University of Antwerp Research Ethics Committee has confirmed that no ethical approval is required.

**Consent to participate:** Not applicable

**Consent for publication:** All authors have read and agreed to the published version of the manuscript.

**Availability of data and materials:** No data was utilized in this study.

**Code availability:** All the code utilized in this research is available in the digital document located at: [https://jriveraespejo.github.io/paper2_manuscript/](https://jriveraespejo.github.io/paper2_manuscript/).  

**AI-assisted technologies in the writing process:** The authors utilized a range of AI-based language tools throughout the preparation of this work. They occasionally employed the tools to refine phrasing and optimize wording, ensuring appropriate language use and enhancing the manuscript's clarity and coherence. The authors take full responsibility for the final content of the publication.

**CRediT authorship contribution statement:** *Conceptualization:* S.G., S.DM., T.vD., and J.M.R.E; *Methodology:* S.DM., T.vD., and J.M.R.E; *Software:* J.M.R.E.; *Validation:* J.M.R.E.; *Formal Analysis:* J.M.R.E.; *Investigation:* J.M.R.E; *Resources:* S.G., S.DM., and T.vD.; *Data curation:* J.M.R.E.; *Writing - original draft:* J.M.R.E.; *Writing - review and editing:* S.G., S.DM., and T.vD.; *Visualization:* J.M.R.E.; *Supervision:* S.G. and S.DM.; *Project administration:* S.G. and S.DM.; *Funding acquisition:* S.G. and S.DM.

<!-- **Acknowledgements:** -->



{{< pagebreak >}}

# Appendix {#sec-appendix .appendix appendix-style=plain}

This section introduces fundamental statistical and causal inference concepts necessary for understanding the core theoretical principles described in @sec-theory. It does not, however, offer a comprehensive overview of causal inference methods. Readers seeking more in-depth understanding may wish to explore introductory papers such as @Pearl_2010, @Rohrer_2018, @Pearl_2019, and @Cinelli_et_al_2020. They may also find it helpful to consult introductory books like @Pearl_et_al_2018, @Neal_2020, and @McElreath_2020. For more advanced study, readers may refer to seminal intermediate papers such as @Neyman_et_al_1923, @Rubin_1974, @Spirtes_et_al_1991, and @Sekhon_2009, as well as books such as @Pearl_2009, @Morgan_et_al_2014, and @Hernan_et_al_2020.

## Empirical research and randomized experiments {#sec-appendix-A .appendix appendix-style=plain}

<!-- 1. What does empirical research do first? -->
Empirical research uses evidence from observation and experimentation to address real-world challenges. In this context, researchers typically formulate their research questions as *estimands* or *targets of inference*, i.e., the specific quantities they seek to determine [@Everitt_et_al_2010]. For instance, researchers might be interested in answering the following question: “To what extent do different teaching methods $(T)$ influence students' ability to produce high-quality written texts $(Y)$?" To investigate this, researchers could randomly assign students to two groups, each exposed to a different teaching method $(T_{i} = \{1,2\})$. Then, they would perform pairwise comparisons, generating a dichotomous outcome $(Y_{i} = \{0,1\})$ showing which student exhibits more of the ability. In this scenario, the research question can be rephrased as the estimand, “*On average*, is there a difference in the ability to produce high-quality written texts between the two groups of students?” and this estimand can be mathematically represented by the random quantity $E[Y_{i}| T_{i}=1] - E[Y_{i}| T_{i}=2]$, where $E[\cdot]$ denotes the expected value.

<!-- 2. What do they do next? -->
Researchers would then proceed to identify the estimands. *Identification* is concerned with determining whether an estimator can accurately compute an estimand based on its assumptions, regardless of random variability [@Schuessler_et_al_2023, pp. 4]. An *estimator* is a method or function that transforms data into an estimate [@Neal_2020]. *Estimates* are numerical values that approximate the estimand and are derived through *estimation*, which refers to the process of integrating data with an estimator [@Everitt_et_al_2010]. The Identification-Estimation flowchart [@McElreath_2020; @Neal_2020] in @fig-IEflow provides a visual representation of the process of transitioning from estimands to estimates. 

<!-- The causal assumptions encoded in a DAG constitute the theoretical model on which identification analysis rests. Identification analysis is concerned with determining whether or not the true value of a parameter can be estimated using the assumptions in the model (graph), regardless of random variability in the data due to small samples [@Schuessler_et_al_2023, pp. 4]. -->

![ Identification-Estimation flowchart. Extracted and slightly modified from @Neal_2020 [pp. 32] ](images/png/IEflow.png){#fig-IEflow fig-align="center" width=35%}

<!-- 3. But, what do we need to produce a good estimate? -->
While numerous methods can approximate an estimand, researchers prioritize estimators with desirable properties that ensure the accuracy of estimates. For instance, the Z-test is an estimator known for its effectiveness in comparing groups' proportions, yielding accurate estimates when the underlying assumptions of the statistic are met [@Kanji_2006]. If this is the case, the Z-test is expressed as a signal-to-noise statistic $Z = (\hat{p}_{1} - \hat{p}_{2})/ \hat{s}_{p}$. The signal is defined as the difference between the groups' sample proportions, $\hat{p}_{1} = \sum_{i=1}^{n_{1}}{Y_{i}/n_{1}}$ and $\hat{p}_{2} = \sum_{i=1}^{n_{2}}{Y_{i}/n_{2}}$, analogous to $E[Y_{i}| T_{i}=1]$ and $E[Y_{i}| T_{i}=2]$, respectively. The noise, represented by $\hat{s}_{p}$, is defined as the unpooled sample variability observed between the two groups. 

<!-- the BTL model [@Bradley_et_al_1952; @Luce_1959] is an estimator known for its effectiveness in modeling pairwise comparisons, yielding accurate estimates for the comparison of two groups, as long as the assumptions of the model are met. Usually these estimates are expressed in terms of the proportions of groups  -->

<!-- 4. But we want these estimands to be causal -->
However, researchers often seek to uncover the mechanisms underlying specific data and establish causal relationships rather than simply estimate associations. In the example, researchers can interpret the associational estimate represented by the Z-statistic as causal. This interpretation relies on the data meeting the assumptions of the Z-test and being collected through a randomized experiment. 

Randomized experiments are widely recognized as the gold standard in evidence-based science [@Hariton_et_al_2018; @Hansson_2014]. This recognition stems from their ability to enable researchers to interpret associational estimates as causal. They achieve this by ensuring data, and by extension an estimator, satisfies several key properties, such as common support, no interference, and consistency [@Morgan_et_al_2014; @Neal_2020]. The most critical property, however, is the elimination of confounding. *Confounding* occurs when an external variable $X$ simultaneously influences the outcome $Y$ and the variable of interest $T$, resulting in spurious associations [@Everitt_et_al_2010]. Randomization addresses this issue by decoupling the association between the intervention allocation $T$ from any other variable $X$ [@Morgan_et_al_2014; @Neal_2020].

<!-- 5. Experiments are not available to everyone, then causal inference comes to the rescue -->
Nevertheless, researchers often face constraints that limit their ability to conduct randomized experiments. These constraints include ethical concerns, such as the assignment of individuals to potentially harmful interventions, and practical limitations, such as the infeasibility of, for example, assigning individuals to genetic modifications or physical impairments [@Neal_2020]. In these cases, causal inference offers a valuable alternative for generating causal estimates and understanding the mechanisms underlying specific data. In addition, the framework can provide significant theoretical insights that can enhance the design of experimental and observational studies [@McElreath_2020]. 


## Identification under causal inference {#sec-appendix-B .appendix appendix-style=plain}

<!-- 1. What is causal inference? -->
Unlike classical statistical modeling, which focuses primarily on summarizing data and inferring associations, the *causal inference* framework is designed to identify causes and estimate their effects using data [@Shaughnessy_et_al_2010; @Neal_2020]. The framework uses rigorous mathematical techniques to address the *fundamental problem of causality* [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. This problem revolves around the question, "What would have happened 'in the world' under different circumstances?" This question introduces the concept of counterfactuals, which are instrumental in defining and identifying causal effects.

<!-- 2. What are counterfactuals? -->
*Counterfactuals* are hypothetical scenarios that are *contrary to fact*, where alternative outcomes resulting from a given cause are neither observed nor observable [@Neal_2020; @Counterfactual_2024]. The structural approach to causal inference [@Pearl_2009; @Pearl_et_al_2016] provides a formal framework for defining counterfactuals. For instance, in the scenario described in @sec-appendix-A, the approach begins by defining the *individual causal effect* (ICE) as the difference between each student's potential outcomes: $\tau_{i} = Y_{i}|do(T_{i}=1) - Y_{i}|do(T_{i}=2)$. Here, $do(T_{i}=t)$ represents the intervention operator, $Y_{i}|do(T_{i}=1)$ represents the potential outcome under intervention $T_{i}=1$, and $Y_{i}|do(T_{i}=1)$ represents the potential outcome under intervention $T_{i}=2$. Note that if a student is assigned to intervention $T_{i}=1$, the potential outcome under $T_{i}=2$ becomes a counterfactual, as it is no longer observed nor observable. To address the challenge of unobserved counterfactuals, the approach extends the ICE to the *average causal effect* (ACE): $\tau = E[\tau_{i}] = E[Y_{i}|do(T_{i}=1)]- E[Y_{i}|do(T_{i}=2)]$, representing the average difference between observed potential outcomes and their counterfactual counterparts.

<!-- [^1]: The potential outcomes approach [@Neyman_et_al_1923; @Rubin_1974] defines the ICE as $\tau_{i} = Y^{1}_{i} - Y^{2}_{i}$, while it defines the ACE as $\tau = E[\tau_{i}] = E[Y^{1}_{i}]- E[Y^{2}_{i}]$. -->

<!-- 3. But how does it work? -->
Even when data originates from an observational study, researchers can identify the ACE from associational estimates using the structural approach. They achieve this by performing statistical conditioning on a *sufficient adjustment set* of variables $X$ [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. This *sufficient* set (potentially empty) must block all non-causal paths between $T$ to $Y$ without opening new ones, ensuring the ACE estimator satisfies several key properties, including confounding elimination. If such a set exists, then $T$ and $Y$ are *d-separated* by $X$ [@Pearl_2009], meaning researchers can estimate the ACE from associational random quantities [@Morgan_et_al_2014]. Naturally, the validity of claims about the effects of $T$ on $Y$ now hinges on the assumption that $X$ serves as a sufficient adjustment set. However, as @Kohler_et_al_2019 [pp. 150] observed, drawing conclusions about the real world from observed data inevitably requires assumptions. This holds true for both observational and experimental data.

For instance, if researchers are unable to conduct the randomized experiments described in @sec-appendix-A and instead rely on observational data, they can still estimate the ACE provided a variable $X$, such as the socio-economic status of the school, blocks all non-causal paths between the teaching method $T$ to the outcome $Y$  without opening any new ones. Under these conditions, the ACE can be estimated from associational quantities as $\tau =$ $E[Y_{i}|do(T_{i}=1)]- E[Y_{i}|do(T_{i}=2)] =$ $E_{X}\left[ E[Y_{i}| T_{i}=1, X] - E[Y_{i}| T_{i}=2, X] \right]$, where $E_{X}[\cdot]$ represents the marginal expected value over $X$ [@Morgan_et_al_2014]. Notably, the approach extends the ACE for a continuous variable $T$ as $\tau =$ $E[Y_{i}|do(T_{i}=t)] =$ $d E_{X}\left[ E[Y_{i}| T_{i}=t, X]\right]/ dt$, ensuring broad applicability across different causal scenarios [@Neal_2020, pp. 45].

<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are. [@Kohler_et_al_2019, pp. 150] -->


## SCMs and DAGs {#sec-appendix-C .appendix appendix-style=plain}

<!-- commands for d-separation -->
\newcommand{\dsep}{\perp\!\!\!\perp}
\newcommand{\ndsep}{\not\!\perp\!\!\!\perp}

<!-- 1. The benefits of SCMs and DAGs -->
The structural approach to causal inference uses SCMs and DAGs to formally and graphically represent the presumed causal structure underlying the ACE [@Pearl_2009; @Pearl_et_al_2016; @Gross_et_al_2018; @Neal_2020]. Assuming the depicted causal structure is correct, SCMs and DAGs serve as *conceptual (theoretical) models* that help researchers determine which statistical models can identify an estimand, thus enabling valid causal inference [@McElreath_2020]. They achieve this by representing various causal structures using only five fundamental building blocks, regardless of complexity [@Neal_2020; @McElreath_2020]. This feature allows researchers to decompose complex structures into manageable components [@McElreath_2020]. Furthermore, SCMs and DAGs can depict causal relationships in a non-parametric and fully interactive way. This flexibility enables feasible ACE identification strategies without requiring detailed specifications of the functional relating the variables, their parameters, or their data types [@Pearl_et_al_2016]. @fig-IEflow shows how theoretical models guide the inference process.

<!-- A heuristic is a strategy that simplifies information to make decisions more quickly, efficiently, and sometimes more accurately than complex methods [@Chow_2015]. -->

<!-- 2. the SCMs -->
Figures [-@fig-dags_scms1], [-@fig-dags_scms2], [-@fig-dags_scms3], [-@fig-dags_scms4], and [-@fig-dags_scms5] display these five fundamental building blocks. The left panels of the figures show the formal mathematical models, represented by the SCMs, defined in terms of a set of *endogenous* variables $V=\{X_{1},X_{2},X_{3}\}$, a set of *exogenous* variables $E=\{e_{X1},e_{X2},e_{X3}\}$, and a set of functions $F=\{f_{X1},f_{X2},f_{X3}\}$ [@Pearl_2009; @Cinelli_et_al_2020]. Endogenous variables are those whose causal mechanisms a researcher chooses to model [@Neal_2020]. In contrast, exogenous variables represent *errors* or *disturbances* arising from omitted factors that the investigator chooses not to model explicitly [@Pearl_2009, pp. 27,68]. Lastly, the functions, referred to as *structural equations*, express the endogenous variables as non-parametric functions of other variables. These functions use the symbol '$:=$' to denote the asymmetrical causal dependence of the variables and the symbol '$\dsep$' to represent *d-separation*, a concept akin to (conditional) independence.

<!-- 3. The DAGs -->
Notably, every SCM has an associated DAG [@Pearl_et_al_2016; @Cinelli_et_al_2020]. The right panels of the figures display these DAGs. A DAG is a graph consisting of nodes connected by edges, where the nodes represent random variables. The term *directed* means that the edges extend from one node to another, with arrows indicating the direction of causal influence. The term *acyclic* implies that the causal influences do not form loops, ensuring the influences do not cycle back on themselves [@McElreath_2020]. DAGs represent observed variables as solid black circles, while they use open circles for unobserved (latent) variables [@Morgan_et_al_2014]. Finally, the arrows in the graphs indicate the expected direction of causal influences between these variables. While DAGs often omit exogenous variables for simplicity (the *standard* representation), including these variables is advantageous (the *magnified* representation shown in the figures), as their inclusion helps to identify potential issues related to conditioning and confounding [@Cinelli_et_al_2020].


::: {#fig-dags_scms1 layout-ncol=2}

::: {#fig-scm_bb1 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{3} & := f_{X3}(e_{X3}) \\
  e_{X1} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::


![DAG](images/png/mdag_bb1.png){#fig-mdag_bb1 fig-align="center" fig-pos="H" width=50%}

Two unconnected nodes
:::


::: {#fig-dags_scms2 layout-ncol=2}

::: {#fig-scm_bb2 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{3} & := f_{X3}(X_{1},e_{X3}) \\
  e_{X1} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb2.png){#fig-mdag_bb2 fig-align="center" fig-pos="H" width=50%}

Two connected nodes or descendant
:::


::: {#fig-dags_scms3 layout-ncol=2}

::: {#fig-scm_bb3 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{2} & := f_{X2}(X_{1},e_{X2}) \\
  X_{3} & := f_{X3}(X_{2},e_{X3}) \\
  e_{X1} & \dsep e_{X2} \\
  e_{X1} & \dsep e_{X3} \\
  e_{X2} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb3.png){#fig-mdag_bb3 fig-align="center" fig-pos="H" width=60%}

Chain or mediator
:::


::: {#fig-dags_scms4 layout-ncol=2}

::: {#fig-scm_bb4 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(X_{2},e_{X1}) \\
  X_{2} & := f_{X2}(e_{X2}) \\
  X_{3} & := f_{X3}(X_{2},e_{X3}) \\
  e_{X1} & \dsep e_{X2} \\
  e_{X1} & \dsep e_{X3} \\
  e_{X2} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb4.png){#fig-mdag_bb4 fig-align="center" fig-pos="H" width=60%}

Fork or confounder
:::


::: {#fig-dags_scms5 layout-ncol=2}

::: {#fig-scm_bb5 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{2} & := f_{X2}(X_{1},X_{3},e_{X2}) \\
  X_{3} & := f_{X3}(e_{X3}) \\
  e_{X1} & \dsep e_{X2} \\
  e_{X1} & \dsep e_{X3} \\
  e_{X2} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb5.png){#fig-mdag_bb5 fig-align="center" fig-pos="H" width=60%}

Collider or inmorality
:::


<!-- 4. Theoretical implications of the basic building block of the SCMS and DAGs -->
A careful examination of the figures highlights the theoretical assumptions underlying these building blocks. Figures [-@fig-scm_bb1] and [-@fig-mdag_bb1] depict two unconnected nodes, representing a scenario where variables $X_{1}$ and $X_{3}$ are not causally related. Figures [-@fig-scm_bb2] and [-@fig-mdag_bb2] illustrate two connected nodes, representing a scenario where a *parent* node $X_{1}$ exerts a causal influence on a *child* node $X_{3}$. In this setup, $X_{3}$ is considered a *descendant* of $X_{1}$. Additionally, $X_{1}$ and $X_{3}$ are described as *adjacent* because an edge directly connects them. Figures [-@fig-scm_bb3] and [-@fig-mdag_bb3] depict a *chain*, where $X_{1}$ influences $X_{2}$, and $X_{2}$ influences $X_{3}$. In this configuration, $X_{1}$ is a parent node of $X_{2}$, which is a parent node of $X_{3}$. This structure creates a *directed path* between $X_{1}$ and $X_{3}$. Consequently, $X_{1}$ is an *ancestor* of $X_{3}$, and $X_{2}$ fully *mediates* the relationship between the two. Figures [-@fig-scm_bb4] and [-@fig-mdag_bb4] illustrate a *fork*, where variables $X_{1}$ and $X_{3}$ are both influenced by $X_{2}$. Here, $X_{2}$ is a parent node that *confounds* the relationship between $X_{1}$ and $X_{3}$. Finally, Figures [-@fig-scm_bb5] and [-@fig-mdag_bb5] show a *collider*, where variables $X_{1}$ and $X_{3}$ are concurrent causes of $X_{2}$. In this configuration, $X_{1}$ and $X_{3}$ are not causally related to each other but both influence $X_{2}$ (an *inmorality*). Notably, in all SCMs, the errors are assumed to be independent of each other and from all other variables in the graph, as evidenced by the pairwise relations $e_{X1} \dsep e_{X2}$, $e_{X1} \dsep e_{X3}$, and $e_{X2} \dsep e_{X3}$.

<!-- 5. Continuing with the motivating example -->
Researchers can use these building blocks to represent the scenario outlined in @sec-appendix-B. Figures [-@fig-scm_example1] and [-@fig-mdag_example1] depict the plausible causal structure for this example, assuming that the variable $X$ (socio-economic status of the school) acts as a confounder in the relationship between the teaching method $T$ and the outcome $Y$. The figures show several descendant, such as $X \rightarrow T$, $X \rightarrow Y$, and $T \rightarrow Y$, and also highlight multiple pairs of unconnected nodes, evident from the relationships $e_{T} \dsep e_{X}$, $e_{T} \dsep e_{Y}$, and $e_{X} \dsep e_{Y}$. Additional, the figures depict one fork, $X \rightarrow \{T, Y\}$, and two colliders: $\{X, e_{T}\} \rightarrow T$ and $\{X, T, e_{Y}\} \rightarrow Y$.

::: {#fig-example layout-ncol=2}

::: {#fig-scm_example1 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  T & := f_{Z}(X,e_{T}) \\
  Y & := f_{Y}(T,X,e_{Y}) \\
  e_{T} & \dsep e_{X} \\
  e_{T} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

SCM
:::


![DAG](images/png/mdag_example1.png){#fig-mdag_example1 fig-align="center" width=60%}

Plausible causal structure the scenario outlined in @sec-appendix-B.
:::


## The probabilistic implications of SCMs and DAGs {#sec-appendix-D .appendix appendix-style=plain}

<!-- 1. How the SCMS and DAGs encode probabilistic information? -->
In addition to their graphical capabilities, SCMs and DAGs can encode probabilistic information about causal structures. They achieve this encoding by relying on three fundamental assumptions: the local Markov, the minimality, and the causal edges assumption. The *local Markov assumption* encodes probabilistic independencies between variables by declaring that nodes in a graph are independent of all its non-descendants, given its parents [@Neal_2020]. Meanwhile, the *minimality assumption* encodes probabilistic dependencies among variables by stating that every pair of adjacent nodes exhibits a dependency [@Neal_2020]. Finally, the *causal edges assumption* encodes causal relationships between variables by declaring that each parent node acts as a direct cause of its children [@Neal_2020]. @fig-ACflow illustrates how these assumptions influence the statistical and causal interpretations of graphs. 

![ The flow of association and causation in graphs. Extracted and slightly modified from @Neal_2020 [pp. 31] ](images/png/ACflow.png){#fig-ACflow fig-align="center" width=80%}


<!-- 2. What are the general implications of this? -->
The encoding of probabilistic information in SCMs and DAGs facilitates the efficient representation of the joint distribution of variables [@Pearl_et_al_2016, pp. 29]. A notable implication of the assumptions underlying this encoding is that any conceptual model described by an SCM and DAG can express the joint distribution of variables as a product of conditional probability distributions (CPDs) in the form $P(child \: | \: parents)$. This property is formally known as the *Bayesian Network factorization* (@eq-net_factor) [@Pearl_et_al_2016, pp. 29; @Neal_2020, pp. 21]. In this factorization, $pa(X_{i})$ denotes the set of variables that are the parents of $X_{i}$.

$$
P(X_{1}, X_{2}, \dots, X_{P}) = \prod^{P}_{p=1} P(X_{i} \: | \: pa(X_{i}) )
$$ {#eq-net_factor}


<!-- 3. What is the net result of this? -->
Ultimately, this encoding enables researchers with conceptual (theoretical) knowledge in the form of an SCM and DAG to predict patterns of (in)dependencies in the data. As highlighted by @Pearl_et_al_2016 [pp. 35], these predictions depend solely on the structure of these conceptual models without requiring the quantitative details of the equations or the distributions of the errors. Moreover, once researchers observe empirical data, the patterns of (in)dependencies in this data can provide significant insights into the validity of the proposed conceptual model. 

<!-- The net result is that a researcher who has scientific knowledge in the form of a structural equation model is able to predict patterns of independencies in the data, based solely on the structure of the model’s graph, without relying on any quantitative information carried by the equations or by the distributions of the errors [@Pearl_et_al_2016, pp. 35]. -->

The concept of predicting patterns of (in)dependencies in the data is more clearly illustrated through the five fundamental building blocks outlined in @sec-appendix-C. 
<!-- For instance,the joint probability for the variables in the SCM [-@fig-scm_bb1] and DAG [-@fig-mdag_bb1] can be expressed in the following form: . Furthermore, the (in)dependencies shared by data sets generated by SCMs and DAGs with the same structure are the following: -->


<!-- SCM [-@fig-scm_bb2] and DAG [-@fig-mdag_bb2] -->


<!-- SCM [-@fig-scm_bb3] and DAG [-@fig-mdag_bb3] -->
<!-- Chain: Ux -> X -> Y -> Z <- Uz [@Pearl_et_al_2016, pp. 37] -->
<!-- 1. Z and Y are dependent -->
<!-- For some z, y, P(Z = z|Y = y) ≠ P(Z = z) -->
<!-- 2. Y and X are dependent -->
<!-- For some y, x, P(Y = y|X = x) ≠ P(Y = y) -->
<!-- 3. Z and X are likely dependent -->
<!-- For some z, x, P(Z = z|X = x) ≠ P(Z = z) -->
<!-- 4. Z and X are independent, conditional on Y -->
<!-- For all x, y, z, P(Z = z|X = x, Y = y) = P(Z = z|Y = y)' -->


<!-- SCM [-@fig-scm_bb4] and DAG [-@fig-mdag_bb4] -->
<!-- Fork: Uy -> Y <- X -> Z <- Uz [@Pearl_et_al_2016, pp. 40] -->
<!-- 1. X and Y are dependent. -->
<!-- For some x, y, P(X = x|Y = y) ≠ P(X = x) -->
<!-- 2. X and Z are dependent. -->
<!-- For some x, z, P(X = x|Z = z) ≠ P(X = x) -->
<!-- 3. Z and Y are likely dependent. -->
<!-- For some z, y, P(Z = z|Y = y) ≠ P(Z = z) -->
<!-- 4. Y and Z are independent, conditional on X. -->
<!-- For all 4x, y, z, P(Y = y|Z = z, X = x) = P(Y = y|X = x) -->


<!-- SCM [-@fig-scm_bb5] and DAG [-@fig-mdag_bb5] -->
<!-- Collider: Ux -> X -> Z <- Y <- Uy [@Pearl_et_al_2016, pp. 31] -->
<!-- 1. X and Z are dependent. -->
<!-- For some x, z, P(X = x|Z = z) ≠ P(X = x) -->
<!-- 2. Y and Z are dependent. -->
<!-- For some y, z, P(Y = y|Z = z) ≠ P(Y = y) -->
<!-- 3. X and Y are independent. -->
<!-- For all x, y, P(X = x|Y = y) = P(X = x) -->
<!-- 4. X and Y are dependent conditional on Z. -->
<!-- For some x, y, z, P(X = x|Y = y, Z = z) ≠ P(X = x|Z = z) -->


<!-- 1. How do we use Bayesian inference? -->
<!-- Researchers can estimate the ACE using Bayesian inference methods. Bayesian inference calculates the probability of a set of parameters $\theta$, enabling researchers to use their distributions to represent the ACE. The approach begins by defining two probability distributions: the likelihood of the data, $P(X_{1}, X_{2}, \dots, X_{P} | \theta)$, and the prior distribution, $P(\theta)$ [@Everitt_et_al_2010]. Here, $X_{P}$ represents a random variable, and for simplicity, $\theta$ denotes a parameter space of dimension one. After observing empirical data, researchers update these priors to posterior distributions using Bayes' rule [@Jeffreys_1998]: -->

<!-- $$ -->
<!-- P(\theta \: | \: X_{1}, X_{2}, \dots, X_{P}) = \frac{P(X_{1}, X_{2}, \dots, X_{P} \: | \: \theta) \cdot P(\theta)}{P(X_{1}, X_{2}, \dots, X_{P})} -->
<!-- $$ {#eq-bayes_rule} -->


<!-- Researchers can further simplify the posterior updating process in @eq-bayes_rule into two steps: integrating new empirical data, which is defined by the likelihood, with the parameter update, which is determined by the priors, as demonstrated in equation @eq-prop_rule. This simplification is possible because the denominator on the right-hand side of @eq-bayes_rule acts as a normalizing constant, independent of $\theta$. -->

<!-- $$ -->
<!-- P(\theta \: | \: X_{1}, X_{2}, \dots, X_{P}) \propto P(X_{1}, X_{2}, \dots, X_{P}\: | \: \theta) \cdot P(\theta) -->
<!-- $$ {#eq-prop_rule} -->

<!-- check: -->
<!-- https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation -->
<!-- https://en.wikipedia.org/wiki/Bayesian_inference -->

<!-- 2. But what is the problem? -->
<!-- Temporarily setting aside the definition of prior distributions, it is important to note that the posterior updating process depends on the assumptions underlying the likelihood of the data. However, as the number of random variables, $p$, increases, this joint distribution becomes quickly intractable [@Neal_2020]. This is evident from @eq-like_chain, where the likelihood distribution is re-expressed in terms of chained conditional distributions.  -->

<!-- $$ -->
<!-- P(X_{1}, X_{2}, \dots, X_{P} \: | \: \theta) = P(X_{1} \: | \: \theta) \prod^{P}_{p=2} P(X_{i} \: | \: X_{i-1}, \dots, X_{1}, \theta ) -->
<!-- $$ {#eq-like_chain} -->


<!-- 3. How do DAGs can help? -->
<!-- To address the complexity of the likelihood, researchers simplify the distribution by assuming that variables exhibit specific local (in)dependencies. These assumptions improve model tractability and streamline the estimation process. Researchers formalize these local (in)dependencies using directed acyclic graphs (DAGs).  -->


<!-- 5. Now, what are those mysterious functions?, and how do they become statistical quantities? -->


<!-- 6. What is the modularity assumption? and where does it lead? -->
<!-- 6.1 the Truncated factorization -->
<!-- 6.2 The law of counterfactuals -->

<!-- 7. Causal mechanism -->
<!-- 7.3 the backdoor criterion (do you need it?) -->

<!-- 5. d-separation -->
<!-- 5.1 Blocked path definition-->



<!-- 6. putting it all together -->
<!-- 6.1. Revising the building block: dependence and independence -->


<!-- Ultimately, DAGs play the important role of identifying which variables should be controlled for to be able to estimate causal effects. -->

<!-- Mention convenient R package daggitty to draw dags and extract the causal assumption inherent in a graph -->


<!-- After detailing how to build graphs and what they imply, Include steps to draw dags using a motivating example -->

<!-- point out that the disturbances are usually stochastic in nature -->


<!-- For instance, in the example outlined in @sec-appendix-C, the collected observational data can be expressed as joint probability $P(X,T,Y)$. Using the chain rule, this probability can be further factorized in $P(X,T,Y) = P(X) P(T|X) P(Y|T,X)$. Although this description of this data does not seem hard   -->

<!-- These building blocks can then guide researchers to identify feasible ACE identification strategies. Researchers can use these building blocks to depict the scenario described in @sec-appendix-B. Assuming the variable $X$ (the socio-economic status of the school) blocks all non-causal paths from the teaching method $T$ to the outcome $Y$. -->

<!-- Conditioning on $T=t$ just means that we are restricting our focus to the subset of the population to those who received treatment $t$. In contrast, an intervention would be to take the whole population and give everyone treatment $t$ [@Neal_2020, pp. 32]. -->



{{< pagebreak >}}

# References {.unnumbered .appendix appendix-style=plain} 

<!-- {.unnumbered} -->

:::{#refs}

:::